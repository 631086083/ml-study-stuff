{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 2\n",
    "------------\n",
    "\n",
    "Previously in `1_notmnist.ipynb`, we created a pickle with formatted datasets for training, development and testing on the [notMNIST dataset](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html).\n",
    "\n",
    "The goal of this assignment is to progressively train deeper and more accurate models using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19456,
     "status": "ok",
     "timestamp": 1449847956073,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "0ddb1607-1fc4-4ddb-de28-6c7ab7fb0c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19723,
     "status": "ok",
     "timestamp": 1449847956364,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "2ba0fc75-1487-4ace-a562-cf81cae82793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "# 进行one-hot编码\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCLVqyQ5vPPH"
   },
   "source": [
    "We're first going to train a multinomial logistic regression using simple gradient descent.\n",
    "\n",
    "TensorFlow works like this:\n",
    "* First you describe the computation that you want to see performed: what the inputs, the variables, and the operations look like. These get created as nodes over a computation graph. This description is all contained within the block below:\n",
    "\n",
    "      with graph.as_default():\n",
    "          ...\n",
    "\n",
    "* Then you can run the operations on this graph as many times as you want by calling `session.run()`, providing it outputs to fetch from the graph that get returned. This runtime operation is all contained in the block below:\n",
    "\n",
    "      with tf.Session(graph=graph) as session:\n",
    "          ...\n",
    "\n",
    "Let's load all the data into TensorFlow and build the computation graph corresponding to our training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Nfv39qvtvOl_"
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 10000\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  # Load the training, validation and test data into constants that are\n",
    "  # attached to the graph.\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  # These are the parameters that we are going to be training. The weight\n",
    "  # matrix will be initialized using random values following a (truncated)\n",
    "  # normal distribution. The biases get initialized to zero.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "  # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "  # it's very common, and it can be optimized). We take the average of this\n",
    "  # cross-entropy across all training examples: that's our loss.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  # We are going to find the minimum of this loss using gradient descent.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  # These are not part of training, but merely here so that we can report\n",
    "  # accuracy figures as we train.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQcL4uqISHjP"
   },
   "source": [
    "Let's run this computation and iterate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 9
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 57454,
     "status": "ok",
     "timestamp": 1449847994134,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "z2cjdenH869W",
    "outputId": "4c037ba1-b526-4d8e-e632-91e2a0333267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 15.412525\n",
      "Training accuracy: 16.8%\n",
      "Validation accuracy: 21.1%\n",
      "Loss at step 100: 2.359865\n",
      "Training accuracy: 72.1%\n",
      "Validation accuracy: 70.1%\n",
      "Loss at step 200: 1.886221\n",
      "Training accuracy: 75.1%\n",
      "Validation accuracy: 72.7%\n",
      "Loss at step 300: 1.628749\n",
      "Training accuracy: 76.5%\n",
      "Validation accuracy: 73.6%\n",
      "Loss at step 400: 1.454124\n",
      "Training accuracy: 77.5%\n",
      "Validation accuracy: 74.0%\n",
      "Loss at step 500: 1.324907\n",
      "Training accuracy: 78.2%\n",
      "Validation accuracy: 74.2%\n",
      "Loss at step 600: 1.224821\n",
      "Training accuracy: 78.8%\n",
      "Validation accuracy: 74.3%\n",
      "Loss at step 700: 1.144405\n",
      "Training accuracy: 79.2%\n",
      "Validation accuracy: 74.7%\n",
      "Loss at step 800: 1.077938\n",
      "Training accuracy: 79.5%\n",
      "Validation accuracy: 74.9%\n",
      "Test accuracy: 82.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "    # and get the loss value and the training predictions returned as numpy\n",
    "    # arrays.\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Training accuracy: %.1f%%' % accuracy(\n",
    "        predictions, train_labels[:train_subset, :]))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x68f-hxRGm3H"
   },
   "source": [
    "Let's now switch to stochastic gradient descent training instead, which is much faster.\n",
    "\n",
    "The graph will be similar, except that instead of holding all the training data into a constant node, we create a `Placeholder` node which will be fed actual data at every call of `session.run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qhPMzWYRGrzM"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmVZESmtG4JH"
   },
   "source": [
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 6
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 66292,
     "status": "ok",
     "timestamp": 1449848003013,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "FoF91pknG_YW",
    "outputId": "d255c80e-954d-4183-ca1c-c7333ce91d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 16.895763\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 15.1%\n",
      "Minibatch loss at step 500: 1.090381\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 1000: 1.525268\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 1500: 0.859106\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 2000: 0.811049\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 2500: 0.935827\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 3000: 1.161114\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.4%\n",
      "Test accuracy: 86.4%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7omWxtvLLxik"
   },
   "source": [
    "---\n",
    "Problem\n",
    "-------\n",
    "\n",
    "Turn the logistic regression example with SGD into a 1-hidden layer neural network with rectified linear units [nn.relu()](https://www.tensorflow.org/versions/r0.7/api_docs/python/nn.html#relu) and 1024 hidden nodes. This model should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the structure of nn is:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEZCAYAAACn5YEqAAAMGGlDQ1BJQ0MgUHJvZmlsZQAASImV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\ngf8P8n8hUltl90sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 神经网络结构\n",
    "from IPython.display import display, Image\n",
    "print(\"the structure of nn is:\")\n",
    "display(Image(filename=\"2_nn.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_layers = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_layers]))\n",
    "  biases1 = tf.Variable(tf.zeros([num_hidden_layers]))\n",
    "  weights2 = tf.Variable(tf.truncated_normal([num_hidden_layers, num_labels]))\n",
    "  biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  \n",
    "  activations1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "  logits = tf.matmul(activations1, weights2) + biases2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(\n",
    "        tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1), weights2) + biases2)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(\n",
    "        tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1), weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 296.450928\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 35.3%\n",
      "Minibatch loss at step 500: 16.984468\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 13.549441\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1500: 5.711242\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2000: 3.536446\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2500: 3.971704\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 3000: 1.994853\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.9%\n",
      "Test accuracy: 89.6%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
