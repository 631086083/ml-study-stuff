{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Anna KaRNNa\n",
    "\n",
    "In this notebook, I'll build a character-wise RNN trained on Anna Karenina, one of my all-time favorite books. It'll be able to generate new text based on the text from the book.\n",
    "\n",
    "This network is based off of Andrej Karpathy's [post on RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and [implementation in Torch](https://github.com/karpathy/char-rnn). Also, some information [here at r2rt](http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html) and from [Sherjil Ozair](https://github.com/sherjilozair/char-rnn-tensorflow) on GitHub. Below is the general architecture of the character-wise RNN.\n",
    "\n",
    "<img src=\"assets/charseq.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First we'll load the text file and convert it into integers for our network to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('anna.txt', 'r') as f:\n",
    "    text=f.read()\n",
    "vocab = set(text)\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "chars = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\r\\n\\r\\n\\r\\nHappy families are all alike; every unhappy family is unhappy in its own\\r\\nway.\\r\\n\\r\\nEve'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31, 66, 57, 74, 78, 61, 76,  3, 16,  1,  0,  1,  0,  1,  0, 38, 57,\n",
       "       74, 74, 81,  3, 64, 57, 69, 65, 70, 65, 61, 75,  3, 57, 76, 61,  3,\n",
       "       57, 70, 70,  3, 57, 70, 65, 67, 61, 26,  3, 61, 80, 61, 76, 81,  3,\n",
       "       77, 72, 66, 57, 74, 74, 81,  3, 64, 57, 69, 65, 70, 81,  3, 65, 75,\n",
       "        3, 77, 72, 66, 57, 74, 74, 81,  3, 65, 72,  3, 65, 78, 75,  3, 71,\n",
       "       79, 72,  1,  0, 79, 57, 81, 15,  1,  0,  1,  0, 33, 80, 61], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now I need to split up the data into batches, and into training and validation sets. I should be making a test set here, but I'm not going to worry about that. My test will be if the network can generate new text.\n",
    "\n",
    "Here I'll make both input and target arrays. The targets are the same as the inputs, except shifted one character over. I'll also drop the last bit of data so that I'll only have completely full batches.\n",
    "\n",
    "The idea here is to make a 2D matrix where the number of rows is equal to the number of batches. Each row will be one long concatenated string from the character data. We'll split this data into a training set and validation set using the `split_frac` keyword. This will keep 90% of the batches in the training set, the other 10% in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def split_data(chars, batch_size, num_steps, split_frac=0.9):\n",
    "    \"\"\" \n",
    "    Split character data into training and validation sets, inputs and targets for each set.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    chars: character array\n",
    "    batch_size: Size of examples in each of batch\n",
    "    num_steps: Number of sequence steps to keep in the input and pass to the network\n",
    "    split_frac: Fraction of batches to keep in the training set\n",
    "    \n",
    "    \n",
    "    Returns train_x, train_y, val_x, val_y\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    slice_size = batch_size * num_steps\n",
    "    n_batches = int(len(chars) / slice_size)\n",
    "    \n",
    "    # Drop the last few characters to make only full batches\n",
    "    x = chars[: n_batches*slice_size]\n",
    "    y = chars[1: n_batches*slice_size + 1]\n",
    "    \n",
    "    # Split the data into batch_size slices, then stack them into a 2D matrix \n",
    "    x = np.stack(np.split(x, batch_size))\n",
    "    y = np.stack(np.split(y, batch_size))\n",
    "    \n",
    "    # Now x and y are arrays with dimensions batch_size x n_batches*num_steps\n",
    "    \n",
    "    # Split into training and validation sets, keep the virst split_frac batches for training\n",
    "    split_idx = int(n_batches*split_frac)\n",
    "    train_x, train_y= x[:, :split_idx*num_steps], y[:, :split_idx*num_steps]\n",
    "    val_x, val_y = x[:, split_idx*num_steps:], y[:, split_idx*num_steps:]\n",
    "    \n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y = split_data(chars, 10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 182000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 66, 57, 74, 78, 61, 76,  3, 16,  1],\n",
       "       [ 3, 74, 76, 61, 75, 75,  3, 66, 61, 76],\n",
       "       [72,  3, 78, 71,  3, 75, 74, 61, 57, 67],\n",
       "       [61, 69, 74, 71, 76, 57, 76, 81,  3, 61],\n",
       "       [ 3,  4, 50, 66, 61, 81,  7, 76, 61,  3],\n",
       "       [72, 72, 71, 78, 65, 59, 61, 62, 15,  3],\n",
       "       [65, 72, 63, 61, 76, 75,  3, 79, 65, 78],\n",
       "       [ 3, 69, 71, 69, 61, 72, 78,  3, 79, 66],\n",
       "       [65, 64, 78,  3, 71, 64,  3, 78, 66, 61],\n",
       "       [70,  3, 62, 57, 81, 13,  3, 57, 72, 62]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I'll write another function to grab batches out of the arrays made by split data. Here each batch will be a sliding window on these arrays with size `batch_size X num_steps`. For example, if we want our network to train on a sequence of 100 characters, `num_steps = 100`. For the next batch, we'll shift this window the next sequence of `num_steps` characters. In this way we can feed batches to the network and the cell states will continue through on each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batch(arrs, num_steps):\n",
    "    batch_size, slice_size = arrs[0].shape\n",
    "    \n",
    "    n_batches = int(slice_size/num_steps)\n",
    "    for b in range(n_batches):\n",
    "        yield [x[:, b*num_steps: (b+1)*num_steps] for x in arrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(num_classes, batch_size=50, num_steps=50, lstm_size=128, num_layers=2,\n",
    "              learning_rate=0.001, grad_clip=5, sampling=False):\n",
    "        \n",
    "    if sampling == True:\n",
    "        batch_size, num_steps = 1, 1\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    with tf.name_scope('inputs'):\n",
    "        inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "        x_one_hot = tf.one_hot(inputs, num_classes, name='x_one_hot')\n",
    "    \n",
    "    with tf.name_scope('targets'):\n",
    "        targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "        y_one_hot = tf.one_hot(targets, num_classes, name='y_one_hot')\n",
    "        y_reshaped = tf.reshape(y_one_hot, [-1, num_classes])\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    # Build the RNN layers\n",
    "    with tf.name_scope(\"RNN_layers\"):\n",
    "        def build_cell(lstm_size, keep_prob):\n",
    "            lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "            drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            return drop\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    with tf.name_scope(\"RNN_init_state\"):\n",
    "        initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    # Run the data through the RNN layers\n",
    "    with tf.name_scope(\"RNN_forward\"):\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=initial_state)\n",
    "    \n",
    "    final_state = state\n",
    "    \n",
    "    # Reshape output so it's a bunch of rows, one row for each cell output\n",
    "    with tf.name_scope('sequence_reshape'):\n",
    "        seq_output = tf.concat(outputs, axis=1,name='seq_output')\n",
    "        output = tf.reshape(seq_output, [-1, lstm_size], name='graph_output')\n",
    "    \n",
    "    # Now connect the RNN putputs to a softmax layer and calculate the cost\n",
    "    with tf.name_scope('logits'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((lstm_size, num_classes), stddev=0.1),\n",
    "                               name='softmax_w')\n",
    "        softmax_b = tf.Variable(tf.zeros(num_classes), name='softmax_b')\n",
    "        logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "\n",
    "    with tf.name_scope('predictions'):\n",
    "        preds = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    \n",
    "    with tf.name_scope('cost'):\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped, name='loss')\n",
    "        cost = tf.reduce_mean(loss, name='cost')\n",
    "\n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    with tf.name_scope('train'):\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "        optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    # Export the nodes \n",
    "    export_nodes = ['inputs', 'targets', 'initial_state', 'final_state',\n",
    "                    'keep_prob', 'cost', 'preds', 'optimizer']\n",
    "    Graph = namedtuple('Graph', export_nodes)\n",
    "    local_dict = locals()\n",
    "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Here I'm defining the hyperparameters for the network. The two you probably haven't seen before are `lstm_size` and `num_layers`. These set the number of hidden units in the LSTM layers and the number of LSTM layers, respectively. Of course, making these bigger will improve the network's performance but you'll have to watch out for overfitting. If your validation loss is much larger than the training loss, you're probably overfitting. Decrease the size of the network or decrease the dropout keep probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_steps = 100\n",
    "lstm_size = 512\n",
    "num_layers = 2\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Write out the graph for TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = build_rnn(len(vocab), \n",
    "                  batch_size=batch_size,\n",
    "                  num_steps=num_steps,\n",
    "                  learning_rate=learning_rate,\n",
    "                  lstm_size=lstm_size,\n",
    "                  num_layers=num_layers)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_writer = tf.summary.FileWriter('./logs/3', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "\n",
    "Time for training which is is pretty straightforward. Here I pass in some data, and get an LSTM state back. Then I pass that state back in to the network so the next batch can continue the state from the previous batch. And every so often (set by `save_every_n`) I calculate the validation loss and save a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p checkpoints/anna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 1/10 ', 'Iteration 1/1810', 'Training loss: 4.4275', '9.0918 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 2/1810', 'Training loss: 4.3808', '6.4469 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 3/1810', 'Training loss: 4.1926', '6.4139 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 4/1810', 'Training loss: 4.2048', '6.4366 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 5/1810', 'Training loss: 4.1429', '6.4795 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 6/1810', 'Training loss: 4.0590', '6.5778 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 7/1810', 'Training loss: 3.9809', '6.5231 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 8/1810', 'Training loss: 3.9139', '6.6373 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 9/1810', 'Training loss: 3.8610', '6.4976 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 10/1810', 'Training loss: 3.8119', '6.4456 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 11/1810', 'Training loss: 3.7707', '6.5642 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 12/1810', 'Training loss: 3.7356', '6.6049 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 13/1810', 'Training loss: 3.7032', '6.5207 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 14/1810', 'Training loss: 3.6737', '6.5170 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 15/1810', 'Training loss: 3.6507', '6.3481 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 16/1810', 'Training loss: 3.6282', '6.5410 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 17/1810', 'Training loss: 3.6080', '6.5312 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 18/1810', 'Training loss: 3.5905', '6.6139 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 19/1810', 'Training loss: 3.5745', '6.3906 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 20/1810', 'Training loss: 3.5595', '6.4974 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 21/1810', 'Training loss: 3.5450', '6.3639 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 22/1810', 'Training loss: 3.5313', '6.4372 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 23/1810', 'Training loss: 3.5194', '6.5811 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 24/1810', 'Training loss: 3.5081', '6.4561 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 25/1810', 'Training loss: 3.4977', '6.4744 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 26/1810', 'Training loss: 3.4880', '6.4179 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 27/1810', 'Training loss: 3.4791', '6.4829 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 28/1810', 'Training loss: 3.4705', '6.4138 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 29/1810', 'Training loss: 3.4624', '6.4142 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 30/1810', 'Training loss: 3.4541', '6.4985 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 31/1810', 'Training loss: 3.4466', '6.4704 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 32/1810', 'Training loss: 3.4399', '6.4050 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 33/1810', 'Training loss: 3.4341', '6.4481 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 34/1810', 'Training loss: 3.4278', '6.4389 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 35/1810', 'Training loss: 3.4212', '6.3214 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 36/1810', 'Training loss: 3.4162', '6.4959 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 37/1810', 'Training loss: 3.4111', '6.3521 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 38/1810', 'Training loss: 3.4053', '6.5095 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 39/1810', 'Training loss: 3.4001', '6.4096 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 40/1810', 'Training loss: 3.3949', '6.3409 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 41/1810', 'Training loss: 3.3896', '6.4356 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 42/1810', 'Training loss: 3.3852', '6.4123 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 43/1810', 'Training loss: 3.3809', '6.3882 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 44/1810', 'Training loss: 3.3765', '6.3262 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 45/1810', 'Training loss: 3.3721', '7.2091 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 46/1810', 'Training loss: 3.3680', '6.4696 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 47/1810', 'Training loss: 3.3640', '6.3896 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 48/1810', 'Training loss: 3.3602', '6.4122 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 49/1810', 'Training loss: 3.3569', '6.7411 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 50/1810', 'Training loss: 3.3538', '6.3367 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 51/1810', 'Training loss: 3.3506', '6.3418 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 52/1810', 'Training loss: 3.3472', '6.3657 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 53/1810', 'Training loss: 3.3440', '6.4470 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 54/1810', 'Training loss: 3.3408', '6.3240 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 55/1810', 'Training loss: 3.3377', '6.3112 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 56/1810', 'Training loss: 3.3348', '6.4431 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 57/1810', 'Training loss: 3.3318', '6.5313 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 58/1810', 'Training loss: 3.3290', '6.4121 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 59/1810', 'Training loss: 3.3262', '6.4042 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 60/1810', 'Training loss: 3.3237', '6.3186 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 61/1810', 'Training loss: 3.3211', '6.4485 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 62/1810', 'Training loss: 3.3183', '6.4072 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 63/1810', 'Training loss: 3.3160', '6.3465 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 64/1810', 'Training loss: 3.3135', '6.2950 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 65/1810', 'Training loss: 3.3114', '6.4780 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 66/1810', 'Training loss: 3.3093', '6.4443 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 67/1810', 'Training loss: 3.3068', '6.4999 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 68/1810', 'Training loss: 3.3045', '6.3960 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 69/1810', 'Training loss: 3.3023', '6.4765 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 70/1810', 'Training loss: 3.3000', '6.4442 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 71/1810', 'Training loss: 3.2977', '6.3600 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 72/1810', 'Training loss: 3.2956', '6.3947 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 73/1810', 'Training loss: 3.2932', '6.4065 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 74/1810', 'Training loss: 3.2911', '6.3651 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 75/1810', 'Training loss: 3.2896', '6.3717 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 76/1810', 'Training loss: 3.2879', '6.3779 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 77/1810', 'Training loss: 3.2863', '6.4112 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 78/1810', 'Training loss: 3.2849', '6.3738 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 79/1810', 'Training loss: 3.2833', '6.3790 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 80/1810', 'Training loss: 3.2820', '6.4124 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 81/1810', 'Training loss: 3.2802', '6.3867 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 82/1810', 'Training loss: 3.2785', '6.4187 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 83/1810', 'Training loss: 3.2768', '6.3380 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 84/1810', 'Training loss: 3.2753', '6.5422 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 85/1810', 'Training loss: 3.2735', '6.3668 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 86/1810', 'Training loss: 3.2719', '6.5036 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 87/1810', 'Training loss: 3.2702', '6.3887 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 88/1810', 'Training loss: 3.2684', '6.4698 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 89/1810', 'Training loss: 3.2667', '6.3996 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 90/1810', 'Training loss: 3.2649', '6.3644 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 91/1810', 'Training loss: 3.2630', '6.3538 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 92/1810', 'Training loss: 3.2615', '6.4286 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 93/1810', 'Training loss: 3.2597', '6.4418 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 94/1810', 'Training loss: 3.2582', '6.4050 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 95/1810', 'Training loss: 3.2564', '6.3180 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 96/1810', 'Training loss: 3.2547', '6.9393 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 97/1810', 'Training loss: 3.2529', '6.4679 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 98/1810', 'Training loss: 3.2510', '6.4309 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 99/1810', 'Training loss: 3.2494', '6.3825 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 100/1810', 'Training loss: 3.2477', '6.4142 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 101/1810', 'Training loss: 3.2459', '6.3934 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 102/1810', 'Training loss: 3.2440', '6.3778 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 103/1810', 'Training loss: 3.2422', '6.4087 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 104/1810', 'Training loss: 3.2403', '6.4030 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 105/1810', 'Training loss: 3.2384', '6.5205 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 106/1810', 'Training loss: 3.2365', '6.4306 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 107/1810', 'Training loss: 3.2346', '6.3982 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 108/1810', 'Training loss: 3.2329', '6.5073 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 109/1810', 'Training loss: 3.2308', '6.3332 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 110/1810', 'Training loss: 3.2288', '6.4725 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 111/1810', 'Training loss: 3.2267', '6.3523 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 112/1810', 'Training loss: 3.2248', '8.1693 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 113/1810', 'Training loss: 3.2227', '7.0623 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 114/1810', 'Training loss: 3.2214', '6.3727 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 115/1810', 'Training loss: 3.2210', '6.4917 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 116/1810', 'Training loss: 3.2202', '3604.2070 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 117/1810', 'Training loss: 3.2190', '6.9037 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 118/1810', 'Training loss: 3.2175', '8.6779 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 119/1810', 'Training loss: 3.2154', '9.0238 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 120/1810', 'Training loss: 3.2132', '8.6077 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 121/1810', 'Training loss: 3.2110', '8.9533 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 122/1810', 'Training loss: 3.2087', '8.6336 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 123/1810', 'Training loss: 3.2065', '8.6193 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 124/1810', 'Training loss: 3.2043', '9.5456 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 125/1810', 'Training loss: 3.2021', '8.8449 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 126/1810', 'Training loss: 3.1998', '8.8274 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 127/1810', 'Training loss: 3.1974', '8.7497 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 128/1810', 'Training loss: 3.1949', '8.7546 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 129/1810', 'Training loss: 3.1922', '8.8495 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 130/1810', 'Training loss: 3.1897', '8.6978 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 131/1810', 'Training loss: 3.1872', '9.0486 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 132/1810', 'Training loss: 3.1847', '8.6986 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 133/1810', 'Training loss: 3.1822', '8.7493 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 134/1810', 'Training loss: 3.1798', '9.1834 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 135/1810', 'Training loss: 3.1771', '8.9460 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 136/1810', 'Training loss: 3.1745', '8.9853 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 137/1810', 'Training loss: 3.1717', '9.1835 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 138/1810', 'Training loss: 3.1690', '8.7672 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 139/1810', 'Training loss: 3.1663', '8.8299 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 140/1810', 'Training loss: 3.1633', '9.1631 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 141/1810', 'Training loss: 3.1604', '8.7971 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 142/1810', 'Training loss: 3.1577', '9.0440 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 143/1810', 'Training loss: 3.1548', '8.9060 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 144/1810', 'Training loss: 3.1519', '8.9676 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 145/1810', 'Training loss: 3.1491', '9.1522 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 146/1810', 'Training loss: 3.1460', '8.9301 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 147/1810', 'Training loss: 3.1430', '9.1278 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 148/1810', 'Training loss: 3.1400', '9.1253 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 149/1810', 'Training loss: 3.1370', '9.1972 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 150/1810', 'Training loss: 3.1340', '8.9624 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 151/1810', 'Training loss: 3.1311', '9.2252 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 152/1810', 'Training loss: 3.1281', '9.8632 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 153/1810', 'Training loss: 3.1250', '9.6207 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 154/1810', 'Training loss: 3.1219', '9.1185 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 155/1810', 'Training loss: 3.1189', '8.8605 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 156/1810', 'Training loss: 3.1160', '9.3762 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 157/1810', 'Training loss: 3.1131', '9.1905 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 158/1810', 'Training loss: 3.1101', '8.9832 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 159/1810', 'Training loss: 3.1068', '9.1250 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 160/1810', 'Training loss: 3.1036', '9.1762 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 161/1810', 'Training loss: 3.1004', '9.2058 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 162/1810', 'Training loss: 3.0972', '9.1783 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 163/1810', 'Training loss: 3.0939', '9.2928 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 164/1810', 'Training loss: 3.0905', '8.9579 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 165/1810', 'Training loss: 3.0872', '9.2546 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 166/1810', 'Training loss: 3.0838', '9.3526 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 167/1810', 'Training loss: 3.0805', '9.1660 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 168/1810', 'Training loss: 3.0771', '9.0111 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 169/1810', 'Training loss: 3.0738', '9.1855 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 170/1810', 'Training loss: 3.0706', '9.1989 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 171/1810', 'Training loss: 3.0672', '9.1633 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 172/1810', 'Training loss: 3.0641', '9.1031 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 173/1810', 'Training loss: 3.0608', '9.1888 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 174/1810', 'Training loss: 3.0575', '9.1963 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 175/1810', 'Training loss: 3.0543', '9.2871 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 176/1810', 'Training loss: 3.0512', '9.5362 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 177/1810', 'Training loss: 3.0480', '9.2137 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 178/1810', 'Training loss: 3.0451', '9.2497 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 179/1810', 'Training loss: 3.0421', '9.3194 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 180/1810', 'Training loss: 3.0391', '9.1594 sec/batch')\n",
      "('Epoch 1/10 ', 'Iteration 181/1810', 'Training loss: 3.0360', '9.2811 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 182/1810', 'Training loss: 2.5324', '9.1190 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 183/1810', 'Training loss: 2.4953', '9.2158 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 184/1810', 'Training loss: 2.4707', '9.4015 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 185/1810', 'Training loss: 2.4622', '9.1161 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 186/1810', 'Training loss: 2.4579', '9.3069 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 187/1810', 'Training loss: 2.4582', '9.3324 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 188/1810', 'Training loss: 2.4542', '9.9134 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 189/1810', 'Training loss: 2.4497', '9.3923 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 190/1810', 'Training loss: 2.4488', '9.2422 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 191/1810', 'Training loss: 2.4463', '9.2565 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 192/1810', 'Training loss: 2.4457', '9.3518 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 193/1810', 'Training loss: 2.4446', '9.5369 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 194/1810', 'Training loss: 2.4430', '9.0532 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 195/1810', 'Training loss: 2.4404', '9.1277 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 196/1810', 'Training loss: 2.4408', '9.2551 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 197/1810', 'Training loss: 2.4389', '9.2470 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 198/1810', 'Training loss: 2.4369', '9.4009 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 199/1810', 'Training loss: 2.4360', '9.1672 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 200/1810', 'Training loss: 2.4369', '9.3805 sec/batch')\n",
      "('Validation loss:', 2.3116391, 'Saving checkpoint!')\n",
      "('Epoch 2/10 ', 'Iteration 201/1810', 'Training loss: 2.4365', '9.3233 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 202/1810', 'Training loss: 2.4364', '9.2822 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 203/1810', 'Training loss: 2.4341', '9.2387 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 204/1810', 'Training loss: 2.4316', '9.1309 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 205/1810', 'Training loss: 2.4303', '9.1802 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 206/1810', 'Training loss: 2.4284', '9.7282 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 207/1810', 'Training loss: 2.4269', '9.1918 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 208/1810', 'Training loss: 2.4254', '9.3780 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 209/1810', 'Training loss: 2.4226', '9.4802 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 210/1810', 'Training loss: 2.4212', '9.2394 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 211/1810', 'Training loss: 2.4195', '9.5553 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 212/1810', 'Training loss: 2.4176', '9.3314 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 213/1810', 'Training loss: 2.4163', '9.4961 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 214/1810', 'Training loss: 2.4145', '9.1504 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 215/1810', 'Training loss: 2.4135', '9.6922 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 216/1810', 'Training loss: 2.4114', '12.3741 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 217/1810', 'Training loss: 2.4104', '14.7767 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 218/1810', 'Training loss: 2.4088', '17.1265 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 219/1810', 'Training loss: 2.4064', '15.1704 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 220/1810', 'Training loss: 2.4046', '14.9887 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 221/1810', 'Training loss: 2.4028', '16.0749 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 222/1810', 'Training loss: 2.4001', '16.6656 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 223/1810', 'Training loss: 2.3982', '16.2591 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 224/1810', 'Training loss: 2.3964', '15.4818 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 225/1810', 'Training loss: 2.3944', '16.9507 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 226/1810', 'Training loss: 2.3923', '16.0673 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 227/1810', 'Training loss: 2.3902', '16.8016 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 228/1810', 'Training loss: 2.3882', '15.8179 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 229/1810', 'Training loss: 2.3860', '16.3588 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 230/1810', 'Training loss: 2.3841', '16.6523 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 231/1810', 'Training loss: 2.3828', '16.0784 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 232/1810', 'Training loss: 2.3812', '15.3978 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 233/1810', 'Training loss: 2.3795', '16.7239 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 234/1810', 'Training loss: 2.3783', '15.4766 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 235/1810', 'Training loss: 2.3765', '16.6415 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 236/1810', 'Training loss: 2.3750', '16.3636 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 237/1810', 'Training loss: 2.3735', '16.6493 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 238/1810', 'Training loss: 2.3720', '16.6222 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 239/1810', 'Training loss: 2.3703', '16.6327 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 240/1810', 'Training loss: 2.3688', '15.9146 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 241/1810', 'Training loss: 2.3677', '16.2030 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 242/1810', 'Training loss: 2.3666', '16.6252 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 243/1810', 'Training loss: 2.3651', '15.8105 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 244/1810', 'Training loss: 2.3636', '16.7996 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 245/1810', 'Training loss: 2.3619', '16.6600 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 246/1810', 'Training loss: 2.3609', '15.2288 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 247/1810', 'Training loss: 2.3600', '16.4672 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 248/1810', 'Training loss: 2.3586', '17.0519 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 249/1810', 'Training loss: 2.3572', '16.7419 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 250/1810', 'Training loss: 2.3554', '16.1177 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 251/1810', 'Training loss: 2.3542', '15.4027 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 252/1810', 'Training loss: 2.3528', '17.9396 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 253/1810', 'Training loss: 2.3513', '17.0097 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 254/1810', 'Training loss: 2.3499', '16.5456 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 255/1810', 'Training loss: 2.3489', '16.2046 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 256/1810', 'Training loss: 2.3477', '17.5238 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 257/1810', 'Training loss: 2.3462', '17.5415 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 258/1810', 'Training loss: 2.3450', '16.7073 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 259/1810', 'Training loss: 2.3438', '16.6654 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 260/1810', 'Training loss: 2.3425', '17.6970 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 261/1810', 'Training loss: 2.3416', '16.9126 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 262/1810', 'Training loss: 2.3403', '16.9018 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 263/1810', 'Training loss: 2.3389', '17.4286 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 264/1810', 'Training loss: 2.3375', '17.6031 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 265/1810', 'Training loss: 2.3365', '16.6021 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 266/1810', 'Training loss: 2.3348', '17.1750 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 267/1810', 'Training loss: 2.3332', '17.5293 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 268/1810', 'Training loss: 2.3316', '17.3933 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 269/1810', 'Training loss: 2.3301', '18.5323 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 270/1810', 'Training loss: 2.3287', '16.6598 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 271/1810', 'Training loss: 2.3274', '17.6427 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 272/1810', 'Training loss: 2.3259', '18.2659 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 273/1810', 'Training loss: 2.3245', '17.5844 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 274/1810', 'Training loss: 2.3231', '17.4317 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 275/1810', 'Training loss: 2.3218', '18.3610 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 276/1810', 'Training loss: 2.3206', '21.4147 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 277/1810', 'Training loss: 2.3192', '21.4161 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 278/1810', 'Training loss: 2.3180', '20.0768 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 279/1810', 'Training loss: 2.3166', '18.4820 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 280/1810', 'Training loss: 2.3152', '18.4048 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 281/1810', 'Training loss: 2.3139', '18.5423 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 282/1810', 'Training loss: 2.3124', '21.0177 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 283/1810', 'Training loss: 2.3111', '19.7313 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 284/1810', 'Training loss: 2.3097', '18.9576 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 285/1810', 'Training loss: 2.3083', '19.4496 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 286/1810', 'Training loss: 2.3074', '20.4634 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 287/1810', 'Training loss: 2.3061', '20.4893 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 288/1810', 'Training loss: 2.3047', '19.9654 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 289/1810', 'Training loss: 2.3037', '18.8045 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 290/1810', 'Training loss: 2.3022', '20.3139 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 291/1810', 'Training loss: 2.3012', '19.7533 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 292/1810', 'Training loss: 2.3001', '21.9547 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 293/1810', 'Training loss: 2.2991', '20.5238 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 294/1810', 'Training loss: 2.2980', '18.7313 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 295/1810', 'Training loss: 2.2970', '18.7664 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 296/1810', 'Training loss: 2.2960', '18.5702 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 297/1810', 'Training loss: 2.2947', '19.6050 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 298/1810', 'Training loss: 2.2934', '19.5025 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 299/1810', 'Training loss: 2.2922', '20.0104 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 300/1810', 'Training loss: 2.2910', '19.4423 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 301/1810', 'Training loss: 2.2898', '19.3058 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 302/1810', 'Training loss: 2.2887', '19.3122 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 303/1810', 'Training loss: 2.2877', '19.5093 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 304/1810', 'Training loss: 2.2865', '20.6815 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 305/1810', 'Training loss: 2.2856', '19.3227 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 306/1810', 'Training loss: 2.2845', '21.0485 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 307/1810', 'Training loss: 2.2834', '20.6507 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 308/1810', 'Training loss: 2.2820', '20.4815 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 309/1810', 'Training loss: 2.2810', '21.0035 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 310/1810', 'Training loss: 2.2799', '20.6123 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 311/1810', 'Training loss: 2.2789', '20.6345 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 312/1810', 'Training loss: 2.2777', '19.8362 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 313/1810', 'Training loss: 2.2768', '22.1375 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 314/1810', 'Training loss: 2.2758', '23.1079 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 315/1810', 'Training loss: 2.2747', '18.6391 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 316/1810', 'Training loss: 2.2733', '20.8717 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 317/1810', 'Training loss: 2.2723', '23.4085 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 318/1810', 'Training loss: 2.2710', '19.8586 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 319/1810', 'Training loss: 2.2703', '20.3501 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 320/1810', 'Training loss: 2.2693', '24.2302 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 321/1810', 'Training loss: 2.2682', '20.6994 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 322/1810', 'Training loss: 2.2672', '20.6483 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 323/1810', 'Training loss: 2.2664', '23.2826 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 324/1810', 'Training loss: 2.2654', '22.0088 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 325/1810', 'Training loss: 2.2644', '25.2928 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 326/1810', 'Training loss: 2.2634', '20.4663 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 327/1810', 'Training loss: 2.2623', '19.5233 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 328/1810', 'Training loss: 2.2613', '20.7671 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 329/1810', 'Training loss: 2.2604', '26.2749 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 330/1810', 'Training loss: 2.2594', '20.7454 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 331/1810', 'Training loss: 2.2584', '23.7135 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 332/1810', 'Training loss: 2.2576', '22.8781 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 333/1810', 'Training loss: 2.2567', '24.1804 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 334/1810', 'Training loss: 2.2560', '21.1682 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 335/1810', 'Training loss: 2.2550', '25.7449 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 336/1810', 'Training loss: 2.2540', '21.6080 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 337/1810', 'Training loss: 2.2531', '20.7572 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 338/1810', 'Training loss: 2.2522', '23.5026 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 339/1810', 'Training loss: 2.2514', '28.6501 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 340/1810', 'Training loss: 2.2504', '23.8545 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 341/1810', 'Training loss: 2.2494', '23.1853 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 342/1810', 'Training loss: 2.2485', '23.9616 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 343/1810', 'Training loss: 2.2476', '26.9990 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 344/1810', 'Training loss: 2.2465', '23.3718 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 345/1810', 'Training loss: 2.2454', '22.1153 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 346/1810', 'Training loss: 2.2445', '25.2427 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 347/1810', 'Training loss: 2.2435', '24.2355 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 348/1810', 'Training loss: 2.2427', '21.8868 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 349/1810', 'Training loss: 2.2417', '24.8549 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 350/1810', 'Training loss: 2.2407', '27.7474 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 351/1810', 'Training loss: 2.2400', '22.9294 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 352/1810', 'Training loss: 2.2390', '26.3344 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 353/1810', 'Training loss: 2.2383', '30.4388 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 354/1810', 'Training loss: 2.2375', '21.5127 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 355/1810', 'Training loss: 2.2364', '23.8066 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 356/1810', 'Training loss: 2.2354', '26.0789 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 357/1810', 'Training loss: 2.2344', '26.2044 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 358/1810', 'Training loss: 2.2334', '25.7967 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 359/1810', 'Training loss: 2.2327', '25.3048 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 360/1810', 'Training loss: 2.2320', '28.3183 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 361/1810', 'Training loss: 2.2312', '20.9292 sec/batch')\n",
      "('Epoch 2/10 ', 'Iteration 362/1810', 'Training loss: 2.2303', '25.7486 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 363/1810', 'Training loss: 2.1532', '26.8772 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 364/1810', 'Training loss: 2.1059', '23.1619 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 365/1810', 'Training loss: 2.0794', '26.8436 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 366/1810', 'Training loss: 2.0736', '28.4795 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 367/1810', 'Training loss: 2.0674', '20.7507 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 368/1810', 'Training loss: 2.0695', '27.3486 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 369/1810', 'Training loss: 2.0642', '20.3972 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 370/1810', 'Training loss: 2.0621', '27.3376 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 371/1810', 'Training loss: 2.0594', '28.1018 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 372/1810', 'Training loss: 2.0564', '25.2776 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 373/1810', 'Training loss: 2.0591', '25.6805 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 374/1810', 'Training loss: 2.0586', '28.6362 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 375/1810', 'Training loss: 2.0578', '24.1643 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 376/1810', 'Training loss: 2.0555', '27.9850 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 377/1810', 'Training loss: 2.0570', '26.2150 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 378/1810', 'Training loss: 2.0540', '25.7835 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 379/1810', 'Training loss: 2.0521', '28.6394 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 380/1810', 'Training loss: 2.0515', '21.8367 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 381/1810', 'Training loss: 2.0516', '30.0333 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 382/1810', 'Training loss: 2.0521', '24.5540 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 383/1810', 'Training loss: 2.0522', '20.2282 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 384/1810', 'Training loss: 2.0503', '20.3312 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 385/1810', 'Training loss: 2.0486', '25.3988 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 386/1810', 'Training loss: 2.0482', '20.3240 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 387/1810', 'Training loss: 2.0466', '26.5483 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 388/1810', 'Training loss: 2.0463', '21.2529 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 389/1810', 'Training loss: 2.0457', '20.1794 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 390/1810', 'Training loss: 2.0432', '23.3599 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 391/1810', 'Training loss: 2.0430', '22.9829 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 392/1810', 'Training loss: 2.0424', '21.2154 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 393/1810', 'Training loss: 2.0417', '21.1574 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 394/1810', 'Training loss: 2.0414', '25.1127 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 395/1810', 'Training loss: 2.0402', '20.2565 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 396/1810', 'Training loss: 2.0397', '20.3398 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 397/1810', 'Training loss: 2.0392', '24.1010 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 398/1810', 'Training loss: 2.0393', '21.9132 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 399/1810', 'Training loss: 2.0386', '22.3659 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 400/1810', 'Training loss: 2.0367', '23.6900 sec/batch')\n",
      "('Validation loss:', 1.9097891, 'Saving checkpoint!')\n",
      "('Epoch 3/10 ', 'Iteration 401/1810', 'Training loss: 2.0363', '19.8100 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 402/1810', 'Training loss: 2.0350', '25.2608 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 403/1810', 'Training loss: 2.0330', '24.8454 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 404/1810', 'Training loss: 2.0320', '20.5250 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 405/1810', 'Training loss: 2.0312', '24.1292 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 406/1810', 'Training loss: 2.0301', '20.1352 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 407/1810', 'Training loss: 2.0296', '21.7071 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 408/1810', 'Training loss: 2.0285', '22.6062 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 409/1810', 'Training loss: 2.0272', '23.7666 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 410/1810', 'Training loss: 2.0255', '20.5310 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 411/1810', 'Training loss: 2.0246', '24.1838 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 412/1810', 'Training loss: 2.0237', '22.4316 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 413/1810', 'Training loss: 2.0229', '20.6621 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 414/1810', 'Training loss: 2.0219', '24.8221 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 415/1810', 'Training loss: 2.0216', '23.6877 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 416/1810', 'Training loss: 2.0208', '20.3567 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 417/1810', 'Training loss: 2.0201', '25.2989 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 418/1810', 'Training loss: 2.0198', '21.0647 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 419/1810', 'Training loss: 2.0191', '20.3628 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 420/1810', 'Training loss: 2.0186', '25.6120 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 421/1810', 'Training loss: 2.0179', '20.1822 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 422/1810', 'Training loss: 2.0174', '20.3032 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 423/1810', 'Training loss: 2.0171', '26.0077 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 424/1810', 'Training loss: 2.0164', '20.8693 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 425/1810', 'Training loss: 2.0159', '20.2189 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 426/1810', 'Training loss: 2.0154', '22.7510 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 427/1810', 'Training loss: 2.0153', '24.9212 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 428/1810', 'Training loss: 2.0155', '20.1714 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 429/1810', 'Training loss: 2.0146', '23.2506 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 430/1810', 'Training loss: 2.0142', '25.5315 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 431/1810', 'Training loss: 2.0131', '20.3921 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 432/1810', 'Training loss: 2.0126', '20.1984 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 433/1810', 'Training loss: 2.0121', '24.1438 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 434/1810', 'Training loss: 2.0112', '20.7399 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 435/1810', 'Training loss: 2.0105', '24.1333 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 436/1810', 'Training loss: 2.0103', '22.1794 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 437/1810', 'Training loss: 2.0099', '20.4483 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 438/1810', 'Training loss: 2.0092', '20.3095 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 439/1810', 'Training loss: 2.0086', '25.3243 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 440/1810', 'Training loss: 2.0080', '20.8626 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 441/1810', 'Training loss: 2.0073', '20.2826 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 442/1810', 'Training loss: 2.0070', '23.7615 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 443/1810', 'Training loss: 2.0062', '20.8797 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 444/1810', 'Training loss: 2.0053', '21.3663 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 445/1810', 'Training loss: 2.0046', '26.6390 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 446/1810', 'Training loss: 2.0041', '20.4515 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 447/1810', 'Training loss: 2.0030', '19.1167 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 448/1810', 'Training loss: 2.0020', '25.2660 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 449/1810', 'Training loss: 2.0009', '20.9994 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 450/1810', 'Training loss: 2.0001', '20.1809 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 451/1810', 'Training loss: 1.9994', '22.0614 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 452/1810', 'Training loss: 1.9987', '22.6973 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 453/1810', 'Training loss: 1.9978', '20.1047 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 454/1810', 'Training loss: 1.9967', '22.9605 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 455/1810', 'Training loss: 1.9960', '22.6061 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 456/1810', 'Training loss: 1.9952', '20.7237 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 457/1810', 'Training loss: 1.9946', '20.4641 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 458/1810', 'Training loss: 1.9939', '24.9167 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 459/1810', 'Training loss: 1.9931', '21.6965 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 460/1810', 'Training loss: 1.9924', '20.4367 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 461/1810', 'Training loss: 1.9914', '23.9842 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 462/1810', 'Training loss: 1.9907', '20.8646 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 463/1810', 'Training loss: 1.9896', '20.1730 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 464/1810', 'Training loss: 1.9887', '23.5710 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 465/1810', 'Training loss: 1.9877', '20.3243 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 466/1810', 'Training loss: 1.9867', '22.7983 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 467/1810', 'Training loss: 1.9863', '20.7464 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 468/1810', 'Training loss: 1.9855', '23.3453 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 469/1810', 'Training loss: 1.9847', '20.5774 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 470/1810', 'Training loss: 1.9841', '21.3075 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 471/1810', 'Training loss: 1.9833', '22.8723 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 472/1810', 'Training loss: 1.9827', '20.4458 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 473/1810', 'Training loss: 1.9820', '21.4221 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 474/1810', 'Training loss: 1.9818', '23.5373 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 475/1810', 'Training loss: 1.9813', '28.8722 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 476/1810', 'Training loss: 1.9807', '23.3811 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 477/1810', 'Training loss: 1.9801', '20.2818 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 478/1810', 'Training loss: 1.9793', '20.6340 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 479/1810', 'Training loss: 1.9785', '22.0840 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 480/1810', 'Training loss: 1.9778', '23.6444 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 481/1810', 'Training loss: 1.9771', '20.3459 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 482/1810', 'Training loss: 1.9765', '23.3297 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 483/1810', 'Training loss: 1.9759', '22.8306 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 484/1810', 'Training loss: 1.9753', '20.7404 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 485/1810', 'Training loss: 1.9745', '26.6532 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 486/1810', 'Training loss: 1.9741', '21.4164 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 487/1810', 'Training loss: 1.9734', '20.2470 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 488/1810', 'Training loss: 1.9726', '21.2743 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 489/1810', 'Training loss: 1.9717', '30.5022 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 490/1810', 'Training loss: 1.9712', '23.0067 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 491/1810', 'Training loss: 1.9705', '20.2637 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 492/1810', 'Training loss: 1.9699', '21.6340 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 493/1810', 'Training loss: 1.9693', '23.4733 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 494/1810', 'Training loss: 1.9689', '23.9454 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 495/1810', 'Training loss: 1.9683', '22.6874 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 496/1810', 'Training loss: 1.9677', '20.3234 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 497/1810', 'Training loss: 1.9671', '24.5505 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 498/1810', 'Training loss: 1.9668', '21.8205 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 499/1810', 'Training loss: 1.9662', '21.0241 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 500/1810', 'Training loss: 1.9659', '22.7429 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 501/1810', 'Training loss: 1.9656', '23.1378 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 502/1810', 'Training loss: 1.9650', '20.2787 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 503/1810', 'Training loss: 1.9645', '25.6417 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 504/1810', 'Training loss: 1.9641', '20.4031 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 505/1810', 'Training loss: 1.9636', '25.5501 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 506/1810', 'Training loss: 1.9632', '21.5801 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 507/1810', 'Training loss: 1.9627', '23.1225 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 508/1810', 'Training loss: 1.9622', '20.3142 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 509/1810', 'Training loss: 1.9617', '24.6707 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 510/1810', 'Training loss: 1.9612', '20.9206 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 511/1810', 'Training loss: 1.9608', '22.7886 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 512/1810', 'Training loss: 1.9602', '21.6966 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 513/1810', 'Training loss: 1.9598', '22.1856 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 514/1810', 'Training loss: 1.9594', '22.2875 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 515/1810', 'Training loss: 1.9592', '20.4813 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 516/1810', 'Training loss: 1.9588', '25.0654 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 517/1810', 'Training loss: 1.9582', '20.4738 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 518/1810', 'Training loss: 1.9578', '25.2752 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 519/1810', 'Training loss: 1.9573', '23.4331 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 520/1810', 'Training loss: 1.9569', '20.3978 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 521/1810', 'Training loss: 1.9563', '20.8629 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 522/1810', 'Training loss: 1.9558', '25.3990 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 523/1810', 'Training loss: 1.9553', '20.2967 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 524/1810', 'Training loss: 1.9548', '20.9681 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 525/1810', 'Training loss: 1.9542', '23.4459 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 526/1810', 'Training loss: 1.9536', '20.9606 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 527/1810', 'Training loss: 1.9531', '23.4478 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 528/1810', 'Training loss: 1.9526', '22.6230 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 529/1810', 'Training loss: 1.9523', '21.8018 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 530/1810', 'Training loss: 1.9517', '20.3281 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 531/1810', 'Training loss: 1.9511', '21.7889 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 532/1810', 'Training loss: 1.9508', '23.0598 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 533/1810', 'Training loss: 1.9503', '25.8924 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 534/1810', 'Training loss: 1.9501', '20.6911 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 535/1810', 'Training loss: 1.9496', '20.1525 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 536/1810', 'Training loss: 1.9490', '24.8588 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 537/1810', 'Training loss: 1.9485', '21.3909 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 538/1810', 'Training loss: 1.9478', '20.7532 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 539/1810', 'Training loss: 1.9472', '23.8799 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 540/1810', 'Training loss: 1.9468', '22.5900 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 541/1810', 'Training loss: 1.9464', '22.0045 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 542/1810', 'Training loss: 1.9459', '20.2687 sec/batch')\n",
      "('Epoch 3/10 ', 'Iteration 543/1810', 'Training loss: 1.9454', '23.2734 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 544/1810', 'Training loss: 1.9316', '21.7915 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 545/1810', 'Training loss: 1.8882', '22.0386 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 546/1810', 'Training loss: 1.8671', '22.7006 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 547/1810', 'Training loss: 1.8623', '22.0409 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 548/1810', 'Training loss: 1.8579', '23.6435 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 549/1810', 'Training loss: 1.8598', '22.8678 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 550/1810', 'Training loss: 1.8529', '22.7662 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 551/1810', 'Training loss: 1.8499', '20.3066 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 552/1810', 'Training loss: 1.8474', '26.3297 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 553/1810', 'Training loss: 1.8452', '21.4628 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 554/1810', 'Training loss: 1.8471', '20.2999 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 555/1810', 'Training loss: 1.8458', '23.7908 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 556/1810', 'Training loss: 1.8452', '22.9594 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 557/1810', 'Training loss: 1.8442', '20.1564 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 558/1810', 'Training loss: 1.8463', '20.3273 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 559/1810', 'Training loss: 1.8422', '23.3886 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 560/1810', 'Training loss: 1.8407', '21.6759 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 561/1810', 'Training loss: 1.8402', '22.1081 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 562/1810', 'Training loss: 1.8402', '23.4601 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 563/1810', 'Training loss: 1.8417', '23.9538 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 564/1810', 'Training loss: 1.8417', '23.4090 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 565/1810', 'Training loss: 1.8401', '23.1304 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 566/1810', 'Training loss: 1.8390', '20.3182 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 567/1810', 'Training loss: 1.8393', '24.1175 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 568/1810', 'Training loss: 1.8386', '20.0182 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 569/1810', 'Training loss: 1.8386', '21.6098 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 570/1810', 'Training loss: 1.8384', '23.1128 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 571/1810', 'Training loss: 1.8361', '21.1409 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 572/1810', 'Training loss: 1.8357', '22.8422 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 573/1810', 'Training loss: 1.8356', '22.6851 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 574/1810', 'Training loss: 1.8350', '22.7786 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 575/1810', 'Training loss: 1.8350', '20.9621 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 576/1810', 'Training loss: 1.8344', '24.1546 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 577/1810', 'Training loss: 1.8339', '23.2784 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 578/1810', 'Training loss: 1.8336', '22.0266 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 579/1810', 'Training loss: 1.8338', '20.4175 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 580/1810', 'Training loss: 1.8333', '26.0723 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 581/1810', 'Training loss: 1.8315', '20.3726 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 582/1810', 'Training loss: 1.8307', '20.5149 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 583/1810', 'Training loss: 1.8294', '24.3263 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 584/1810', 'Training loss: 1.8275', '20.4270 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 585/1810', 'Training loss: 1.8266', '23.9671 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 586/1810', 'Training loss: 1.8256', '22.3408 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 587/1810', 'Training loss: 1.8245', '22.5897 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 588/1810', 'Training loss: 1.8244', '20.3521 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 589/1810', 'Training loss: 1.8237', '24.1672 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 590/1810', 'Training loss: 1.8227', '21.4221 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 591/1810', 'Training loss: 1.8215', '20.6881 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 592/1810', 'Training loss: 1.8209', '24.1826 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 593/1810', 'Training loss: 1.8205', '24.8599 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 594/1810', 'Training loss: 1.8201', '20.2509 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 595/1810', 'Training loss: 1.8193', '20.4553 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 596/1810', 'Training loss: 1.8194', '23.4286 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 597/1810', 'Training loss: 1.8188', '20.7688 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 598/1810', 'Training loss: 1.8182', '23.5906 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 599/1810', 'Training loss: 1.8181', '22.0734 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 600/1810', 'Training loss: 1.8176', '20.2838 sec/batch')\n",
      "('Validation loss:', 1.6931177, 'Saving checkpoint!')\n",
      "('Epoch 4/10 ', 'Iteration 601/1810', 'Training loss: 1.8180', '20.5621 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 602/1810', 'Training loss: 1.8177', '21.9204 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 603/1810', 'Training loss: 1.8174', '22.8419 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 604/1810', 'Training loss: 1.8174', '23.6922 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 605/1810', 'Training loss: 1.8167', '20.7318 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 606/1810', 'Training loss: 1.8166', '21.7556 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 607/1810', 'Training loss: 1.8162', '22.9283 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 608/1810', 'Training loss: 1.8166', '20.2146 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 609/1810', 'Training loss: 1.8171', '23.3266 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 610/1810', 'Training loss: 1.8165', '20.9730 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 611/1810', 'Training loss: 1.8165', '23.6697 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 612/1810', 'Training loss: 1.8158', '20.7444 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 613/1810', 'Training loss: 1.8155', '22.6362 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 614/1810', 'Training loss: 1.8150', '26.1561 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 615/1810', 'Training loss: 1.8145', '21.8977 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 616/1810', 'Training loss: 1.8142', '22.9284 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 617/1810', 'Training loss: 1.8142', '23.1373 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 618/1810', 'Training loss: 1.8140', '20.5375 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 619/1810', 'Training loss: 1.8135', '25.8348 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 620/1810', 'Training loss: 1.8133', '20.3897 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 621/1810', 'Training loss: 1.8129', '23.4435 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 622/1810', 'Training loss: 1.8122', '21.5558 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 623/1810', 'Training loss: 1.8122', '23.0852 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 624/1810', 'Training loss: 1.8117', '20.2853 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 625/1810', 'Training loss: 1.8111', '23.0988 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 626/1810', 'Training loss: 1.8107', '22.6006 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 627/1810', 'Training loss: 1.8101', '20.5837 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 628/1810', 'Training loss: 1.8094', '20.7636 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 629/1810', 'Training loss: 1.8084', '25.3288 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 630/1810', 'Training loss: 1.8076', '21.4264 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 631/1810', 'Training loss: 1.8071', '22.9186 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 632/1810', 'Training loss: 1.8065', '23.2267 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 633/1810', 'Training loss: 1.8059', '20.7502 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 634/1810', 'Training loss: 1.8053', '23.2453 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 635/1810', 'Training loss: 1.8043', '22.0340 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 636/1810', 'Training loss: 1.8038', '20.3869 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 637/1810', 'Training loss: 1.8032', '23.7849 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 638/1810', 'Training loss: 1.8027', '23.0342 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 639/1810', 'Training loss: 1.8021', '21.5900 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 640/1810', 'Training loss: 1.8016', '20.3023 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 641/1810', 'Training loss: 1.8011', '23.9953 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 642/1810', 'Training loss: 1.8004', '20.9095 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 643/1810', 'Training loss: 1.8001', '20.2179 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 644/1810', 'Training loss: 1.7992', '28.5282 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 645/1810', 'Training loss: 1.7984', '23.5613 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 646/1810', 'Training loss: 1.7976', '21.4322 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 647/1810', 'Training loss: 1.7968', '26.3855 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 648/1810', 'Training loss: 1.7967', '20.2255 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 649/1810', 'Training loss: 1.7960', '21.8953 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 650/1810', 'Training loss: 1.7954', '24.4443 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 651/1810', 'Training loss: 1.7951', '20.2478 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 652/1810', 'Training loss: 1.7944', '24.8882 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 653/1810', 'Training loss: 1.7939', '21.0855 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 654/1810', 'Training loss: 1.7935', '21.1330 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 655/1810', 'Training loss: 1.7933', '23.4412 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 656/1810', 'Training loss: 1.7931', '21.9638 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 657/1810', 'Training loss: 1.7927', '22.7178 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 658/1810', 'Training loss: 1.7922', '20.2461 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 659/1810', 'Training loss: 1.7915', '26.2780 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 660/1810', 'Training loss: 1.7909', '24.1543 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 661/1810', 'Training loss: 1.7903', '20.3195 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 662/1810', 'Training loss: 1.7898', '25.0941 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 663/1810', 'Training loss: 1.7892', '20.6886 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 664/1810', 'Training loss: 1.7886', '20.3272 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 665/1810', 'Training loss: 1.7882', '20.5995 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 666/1810', 'Training loss: 1.7876', '25.1853 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 667/1810', 'Training loss: 1.7876', '21.2713 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 668/1810', 'Training loss: 1.7870', '22.6026 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 669/1810', 'Training loss: 1.7865', '22.4538 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 670/1810', 'Training loss: 1.7858', '22.7549 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 671/1810', 'Training loss: 1.7855', '20.4522 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 672/1810', 'Training loss: 1.7850', '23.7108 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 673/1810', 'Training loss: 1.7846', '20.3858 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 674/1810', 'Training loss: 1.7842', '26.1581 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 675/1810', 'Training loss: 1.7839', '21.9409 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 676/1810', 'Training loss: 1.7836', '20.5752 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 677/1810', 'Training loss: 1.7829', '23.4731 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 678/1810', 'Training loss: 1.7824', '23.1331 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 679/1810', 'Training loss: 1.7820', '20.1630 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 680/1810', 'Training loss: 1.7815', '24.7454 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 681/1810', 'Training loss: 1.7812', '20.4410 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 682/1810', 'Training loss: 1.7810', '23.8026 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 683/1810', 'Training loss: 1.7805', '21.1846 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 684/1810', 'Training loss: 1.7801', '22.8977 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 685/1810', 'Training loss: 1.7798', '20.3526 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 686/1810', 'Training loss: 1.7795', '24.1297 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 687/1810', 'Training loss: 1.7791', '21.9792 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 688/1810', 'Training loss: 1.7788', '20.2968 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 689/1810', 'Training loss: 1.7784', '24.8795 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 690/1810', 'Training loss: 1.7780', '22.8775 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 691/1810', 'Training loss: 1.7776', '20.3478 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 692/1810', 'Training loss: 1.7774', '26.3897 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 693/1810', 'Training loss: 1.7769', '23.7372 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 694/1810', 'Training loss: 1.7766', '20.3468 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 695/1810', 'Training loss: 1.7764', '20.3264 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 696/1810', 'Training loss: 1.7763', '24.5962 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 697/1810', 'Training loss: 1.7760', '20.3461 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 698/1810', 'Training loss: 1.7754', '23.9053 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 699/1810', 'Training loss: 1.7752', '22.8757 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 700/1810', 'Training loss: 1.7747', '20.9928 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 701/1810', 'Training loss: 1.7745', '22.8590 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 702/1810', 'Training loss: 1.7741', '22.7262 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 703/1810', 'Training loss: 1.7738', '23.2637 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 704/1810', 'Training loss: 1.7736', '24.8374 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 705/1810', 'Training loss: 1.7732', '20.1820 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 706/1810', 'Training loss: 1.7727', '21.4347 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 707/1810', 'Training loss: 1.7721', '22.5834 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 708/1810', 'Training loss: 1.7717', '22.4492 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 709/1810', 'Training loss: 1.7714', '23.3021 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 710/1810', 'Training loss: 1.7712', '21.6908 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 711/1810', 'Training loss: 1.7708', '22.9292 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 712/1810', 'Training loss: 1.7705', '20.2510 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 713/1810', 'Training loss: 1.7703', '23.9432 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 714/1810', 'Training loss: 1.7701', '20.8092 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 715/1810', 'Training loss: 1.7700', '22.3135 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 716/1810', 'Training loss: 1.7697', '23.1873 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 717/1810', 'Training loss: 1.7692', '21.6571 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 718/1810', 'Training loss: 1.7688', '23.5444 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 719/1810', 'Training loss: 1.7683', '21.9710 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 720/1810', 'Training loss: 1.7680', '23.0008 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 721/1810', 'Training loss: 1.7678', '22.8585 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 722/1810', 'Training loss: 1.7675', '20.3196 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 723/1810', 'Training loss: 1.7673', '22.8789 sec/batch')\n",
      "('Epoch 4/10 ', 'Iteration 724/1810', 'Training loss: 1.7669', '22.9403 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 725/1810', 'Training loss: 1.7791', '20.9357 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 726/1810', 'Training loss: 1.7407', '21.1824 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 727/1810', 'Training loss: 1.7203', '25.0082 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 728/1810', 'Training loss: 1.7176', '20.3348 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 729/1810', 'Training loss: 1.7132', '22.6112 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 730/1810', 'Training loss: 1.7143', '22.9260 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 731/1810', 'Training loss: 1.7075', '20.3197 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 732/1810', 'Training loss: 1.7048', '22.4155 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 733/1810', 'Training loss: 1.7029', '25.2727 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 734/1810', 'Training loss: 1.6994', '20.4691 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 735/1810', 'Training loss: 1.7020', '22.2852 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 736/1810', 'Training loss: 1.7000', '24.1813 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 737/1810', 'Training loss: 1.6997', '20.3077 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 738/1810', 'Training loss: 1.6990', '23.1976 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 739/1810', 'Training loss: 1.7008', '21.5300 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 740/1810', 'Training loss: 1.6976', '21.9276 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 741/1810', 'Training loss: 1.6957', '20.6831 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 742/1810', 'Training loss: 1.6956', '24.5771 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 743/1810', 'Training loss: 1.6950', '20.4506 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 744/1810', 'Training loss: 1.6964', '20.4042 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 745/1810', 'Training loss: 1.6961', '24.0475 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 746/1810', 'Training loss: 1.6952', '20.4986 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 747/1810', 'Training loss: 1.6938', '23.6175 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 748/1810', 'Training loss: 1.6939', '22.5951 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 749/1810', 'Training loss: 1.6933', '20.3704 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 750/1810', 'Training loss: 1.6930', '23.8200 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 751/1810', 'Training loss: 1.6934', '20.6825 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 752/1810', 'Training loss: 1.6913', '23.8494 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 753/1810', 'Training loss: 1.6915', '20.3011 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 754/1810', 'Training loss: 1.6916', '22.7536 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 755/1810', 'Training loss: 1.6914', '21.4486 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 756/1810', 'Training loss: 1.6915', '22.0205 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 757/1810', 'Training loss: 1.6912', '20.7120 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 758/1810', 'Training loss: 1.6907', '23.4375 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 759/1810', 'Training loss: 1.6907', '20.3063 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 760/1810', 'Training loss: 1.6916', '20.5797 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 761/1810', 'Training loss: 1.6910', '25.6015 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 762/1810', 'Training loss: 1.6894', '20.3649 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 763/1810', 'Training loss: 1.6889', '22.3149 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 764/1810', 'Training loss: 1.6877', '23.4028 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 765/1810', 'Training loss: 1.6862', '20.3410 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 766/1810', 'Training loss: 1.6855', '23.1013 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 767/1810', 'Training loss: 1.6847', '20.8840 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 768/1810', 'Training loss: 1.6838', '22.4645 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 769/1810', 'Training loss: 1.6836', '20.2744 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 770/1810', 'Training loss: 1.6830', '23.4807 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 771/1810', 'Training loss: 1.6819', '20.4735 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 772/1810', 'Training loss: 1.6810', '22.6124 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 773/1810', 'Training loss: 1.6808', '21.6363 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 774/1810', 'Training loss: 1.6805', '21.0708 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 775/1810', 'Training loss: 1.6802', '23.1173 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 776/1810', 'Training loss: 1.6796', '21.6938 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 777/1810', 'Training loss: 1.6797', '21.6550 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 778/1810', 'Training loss: 1.6793', '22.1976 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 779/1810', 'Training loss: 1.6789', '25.0483 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 780/1810', 'Training loss: 1.6790', '20.3437 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 781/1810', 'Training loss: 1.6787', '22.5340 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 782/1810', 'Training loss: 1.6785', '21.7487 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 783/1810', 'Training loss: 1.6782', '22.3151 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 784/1810', 'Training loss: 1.6779', '20.2268 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 785/1810', 'Training loss: 1.6780', '25.2542 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 786/1810', 'Training loss: 1.6774', '22.1042 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 787/1810', 'Training loss: 1.6772', '19.4563 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 788/1810', 'Training loss: 1.6770', '23.6397 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 789/1810', 'Training loss: 1.6775', '24.5737 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 790/1810', 'Training loss: 1.6780', '20.7840 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 791/1810', 'Training loss: 1.6771', '20.3986 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 792/1810', 'Training loss: 1.6772', '26.1155 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 793/1810', 'Training loss: 1.6764', '20.7741 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 794/1810', 'Training loss: 1.6763', '23.0084 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 795/1810', 'Training loss: 1.6760', '24.5536 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 796/1810', 'Training loss: 1.6755', '20.3909 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 797/1810', 'Training loss: 1.6754', '22.4361 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 798/1810', 'Training loss: 1.6754', '23.1964 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 799/1810', 'Training loss: 1.6752', '20.3384 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 800/1810', 'Training loss: 1.6749', '20.5546 sec/batch')\n",
      "('Validation loss:', 1.5361898, 'Saving checkpoint!')\n",
      "('Epoch 5/10 ', 'Iteration 801/1810', 'Training loss: 1.6754', '19.9815 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 802/1810', 'Training loss: 1.6750', '21.4906 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 803/1810', 'Training loss: 1.6744', '23.3109 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 804/1810', 'Training loss: 1.6742', '22.0251 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 805/1810', 'Training loss: 1.6741', '22.1402 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 806/1810', 'Training loss: 1.6735', '23.0466 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 807/1810', 'Training loss: 1.6732', '22.3740 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 808/1810', 'Training loss: 1.6727', '20.5905 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 809/1810', 'Training loss: 1.6721', '22.7041 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 810/1810', 'Training loss: 1.6713', '23.6190 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 811/1810', 'Training loss: 1.6707', '20.3531 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 812/1810', 'Training loss: 1.6704', '24.5774 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 813/1810', 'Training loss: 1.6701', '22.6955 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 814/1810', 'Training loss: 1.6696', '21.4917 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 815/1810', 'Training loss: 1.6690', '25.1601 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 816/1810', 'Training loss: 1.6681', '24.9602 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 817/1810', 'Training loss: 1.6678', '20.2278 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 818/1810', 'Training loss: 1.6672', '20.5321 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 819/1810', 'Training loss: 1.6669', '24.2412 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 820/1810', 'Training loss: 1.6664', '22.3439 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 821/1810', 'Training loss: 1.6660', '23.4167 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 822/1810', 'Training loss: 1.6656', '25.5554 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 823/1810', 'Training loss: 1.6649', '20.4881 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 824/1810', 'Training loss: 1.6647', '20.4829 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 825/1810', 'Training loss: 1.6638', '24.5963 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 826/1810', 'Training loss: 1.6631', '21.0013 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 827/1810', 'Training loss: 1.6624', '24.4178 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 828/1810', 'Training loss: 1.6618', '20.1501 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 829/1810', 'Training loss: 1.6618', '21.9925 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 830/1810', 'Training loss: 1.6614', '24.8170 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 831/1810', 'Training loss: 1.6609', '22.1191 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 832/1810', 'Training loss: 1.6608', '21.7247 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 833/1810', 'Training loss: 1.6603', '23.9147 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 834/1810', 'Training loss: 1.6600', '20.3492 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 835/1810', 'Training loss: 1.6597', '25.4638 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 836/1810', 'Training loss: 1.6596', '20.1089 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 837/1810', 'Training loss: 1.6596', '23.5463 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 838/1810', 'Training loss: 1.6593', '21.1635 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 839/1810', 'Training loss: 1.6590', '22.4903 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 840/1810', 'Training loss: 1.6584', '22.7436 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 841/1810', 'Training loss: 1.6580', '20.2639 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 842/1810', 'Training loss: 1.6577', '24.0320 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 843/1810', 'Training loss: 1.6572', '21.3742 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 844/1810', 'Training loss: 1.6568', '21.1746 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 845/1810', 'Training loss: 1.6564', '26.2258 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 846/1810', 'Training loss: 1.6561', '22.9124 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 847/1810', 'Training loss: 1.6555', '20.9151 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 848/1810', 'Training loss: 1.6555', '21.8352 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 849/1810', 'Training loss: 1.6549', '23.0396 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 850/1810', 'Training loss: 1.6544', '20.4170 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 851/1810', 'Training loss: 1.6538', '20.2442 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 852/1810', 'Training loss: 1.6535', '24.0272 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 853/1810', 'Training loss: 1.6532', '21.6036 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 854/1810', 'Training loss: 1.6529', '22.1173 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 855/1810', 'Training loss: 1.6526', '22.3475 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 856/1810', 'Training loss: 1.6523', '20.3042 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 857/1810', 'Training loss: 1.6521', '22.4770 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 858/1810', 'Training loss: 1.6516', '22.7149 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 859/1810', 'Training loss: 1.6513', '21.9870 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 860/1810', 'Training loss: 1.6511', '24.4379 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 861/1810', 'Training loss: 1.6507', '22.4387 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 862/1810', 'Training loss: 1.6505', '20.7723 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 863/1810', 'Training loss: 1.6503', '20.0168 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 864/1810', 'Training loss: 1.6499', '23.9910 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 865/1810', 'Training loss: 1.6497', '22.9281 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 866/1810', 'Training loss: 1.6495', '21.1723 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 867/1810', 'Training loss: 1.6493', '20.2614 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 868/1810', 'Training loss: 1.6492', '24.2620 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 869/1810', 'Training loss: 1.6491', '20.4121 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 870/1810', 'Training loss: 1.6488', '24.2736 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 871/1810', 'Training loss: 1.6486', '20.2079 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 872/1810', 'Training loss: 1.6484', '21.5220 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 873/1810', 'Training loss: 1.6484', '22.5392 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 874/1810', 'Training loss: 1.6481', '24.9222 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 875/1810', 'Training loss: 1.6480', '22.3781 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 876/1810', 'Training loss: 1.6479', '20.5149 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 877/1810', 'Training loss: 1.6479', '23.9961 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 878/1810', 'Training loss: 1.6477', '20.3373 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 879/1810', 'Training loss: 1.6472', '20.2098 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 880/1810', 'Training loss: 1.6470', '23.2610 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 881/1810', 'Training loss: 1.6466', '21.8040 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 882/1810', 'Training loss: 1.6464', '20.2441 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 883/1810', 'Training loss: 1.6461', '22.0474 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 884/1810', 'Training loss: 1.6458', '22.7167 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 885/1810', 'Training loss: 1.6456', '20.2758 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 886/1810', 'Training loss: 1.6453', '24.8788 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 887/1810', 'Training loss: 1.6448', '20.9228 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 888/1810', 'Training loss: 1.6444', '20.2682 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 889/1810', 'Training loss: 1.6441', '26.8707 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 890/1810', 'Training loss: 1.6440', '20.8314 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 891/1810', 'Training loss: 1.6439', '19.1381 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 892/1810', 'Training loss: 1.6435', '26.9029 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 893/1810', 'Training loss: 1.6432', '23.3165 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 894/1810', 'Training loss: 1.6432', '20.3675 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 895/1810', 'Training loss: 1.6430', '20.4746 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 896/1810', 'Training loss: 1.6430', '23.1434 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 897/1810', 'Training loss: 1.6428', '23.4165 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 898/1810', 'Training loss: 1.6424', '22.2923 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 899/1810', 'Training loss: 1.6421', '22.3156 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 900/1810', 'Training loss: 1.6417', '20.2645 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 901/1810', 'Training loss: 1.6413', '23.0171 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 902/1810', 'Training loss: 1.6412', '22.2321 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 903/1810', 'Training loss: 1.6409', '20.9544 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 904/1810', 'Training loss: 1.6408', '27.1561 sec/batch')\n",
      "('Epoch 5/10 ', 'Iteration 905/1810', 'Training loss: 1.6404', '20.2917 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 906/1810', 'Training loss: 1.6773', '20.1670 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 907/1810', 'Training loss: 1.6343', '23.1628 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 908/1810', 'Training loss: 1.6137', '23.1933 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 909/1810', 'Training loss: 1.6103', '20.2137 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 910/1810', 'Training loss: 1.6056', '23.5655 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 911/1810', 'Training loss: 1.6048', '23.4618 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 912/1810', 'Training loss: 1.5984', '19.8839 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 913/1810', 'Training loss: 1.5952', '20.2954 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 914/1810', 'Training loss: 1.5922', '25.3742 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 915/1810', 'Training loss: 1.5881', '20.2751 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 916/1810', 'Training loss: 1.5897', '22.1453 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 917/1810', 'Training loss: 1.5873', '23.0766 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 918/1810', 'Training loss: 1.5862', '20.4278 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 919/1810', 'Training loss: 1.5852', '21.8673 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 920/1810', 'Training loss: 1.5863', '25.4268 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 921/1810', 'Training loss: 1.5831', '20.4156 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 922/1810', 'Training loss: 1.5810', '20.2297 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 923/1810', 'Training loss: 1.5811', '22.0719 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 924/1810', 'Training loss: 1.5808', '22.0678 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 925/1810', 'Training loss: 1.5820', '20.8833 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 926/1810', 'Training loss: 1.5818', '21.7610 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 927/1810', 'Training loss: 1.5807', '22.2412 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 928/1810', 'Training loss: 1.5799', '20.3709 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 929/1810', 'Training loss: 1.5806', '21.2465 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 930/1810', 'Training loss: 1.5794', '23.4374 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 931/1810', 'Training loss: 1.5796', '20.2271 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 932/1810', 'Training loss: 1.5801', '21.1923 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 933/1810', 'Training loss: 1.5780', '23.1321 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 934/1810', 'Training loss: 1.5777', '21.4574 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 935/1810', 'Training loss: 1.5776', '23.0947 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 936/1810', 'Training loss: 1.5775', '23.9972 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 937/1810', 'Training loss: 1.5777', '19.5757 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 938/1810', 'Training loss: 1.5774', '22.7910 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 939/1810', 'Training loss: 1.5770', '24.0271 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 940/1810', 'Training loss: 1.5769', '20.4231 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 941/1810', 'Training loss: 1.5775', '20.6703 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 942/1810', 'Training loss: 1.5773', '20.2417 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 943/1810', 'Training loss: 1.5758', '23.3716 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 944/1810', 'Training loss: 1.5750', '20.4238 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 945/1810', 'Training loss: 1.5737', '23.7655 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 946/1810', 'Training loss: 1.5723', '20.2044 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 947/1810', 'Training loss: 1.5717', '20.6580 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 948/1810', 'Training loss: 1.5706', '22.9125 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 949/1810', 'Training loss: 1.5697', '23.4870 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 950/1810', 'Training loss: 1.5695', '22.4134 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 951/1810', 'Training loss: 1.5686', '20.4046 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 952/1810', 'Training loss: 1.5674', '20.8721 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 953/1810', 'Training loss: 1.5668', '20.3201 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 954/1810', 'Training loss: 1.5664', '25.4347 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 955/1810', 'Training loss: 1.5663', '20.4967 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 956/1810', 'Training loss: 1.5657', '20.3651 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 957/1810', 'Training loss: 1.5649', '23.0189 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 958/1810', 'Training loss: 1.5651', '21.7223 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 959/1810', 'Training loss: 1.5648', '20.1993 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 960/1810', 'Training loss: 1.5644', '20.2558 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 961/1810', 'Training loss: 1.5647', '24.8267 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 962/1810', 'Training loss: 1.5645', '20.3346 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 963/1810', 'Training loss: 1.5643', '19.2569 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 964/1810', 'Training loss: 1.5641', '29.2814 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 965/1810', 'Training loss: 1.5638', '21.5379 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 966/1810', 'Training loss: 1.5640', '19.3196 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 967/1810', 'Training loss: 1.5635', '23.8547 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 968/1810', 'Training loss: 1.5633', '21.1741 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 969/1810', 'Training loss: 1.5630', '21.4029 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 970/1810', 'Training loss: 1.5636', '23.8099 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 971/1810', 'Training loss: 1.5642', '20.4733 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 972/1810', 'Training loss: 1.5635', '20.2798 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 973/1810', 'Training loss: 1.5636', '24.3094 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 974/1810', 'Training loss: 1.5629', '22.6942 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 975/1810', 'Training loss: 1.5626', '20.3244 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 976/1810', 'Training loss: 1.5623', '20.2813 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 977/1810', 'Training loss: 1.5620', '20.2293 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 978/1810', 'Training loss: 1.5618', '23.7550 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 979/1810', 'Training loss: 1.5619', '21.4735 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 980/1810', 'Training loss: 1.5618', '24.7910 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 981/1810', 'Training loss: 1.5615', '21.3914 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 982/1810', 'Training loss: 1.5615', '22.2670 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 983/1810', 'Training loss: 1.5612', '20.2309 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 984/1810', 'Training loss: 1.5608', '24.2851 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 985/1810', 'Training loss: 1.5609', '20.7687 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 986/1810', 'Training loss: 1.5608', '22.9091 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 987/1810', 'Training loss: 1.5603', '20.7754 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 988/1810', 'Training loss: 1.5600', '20.3887 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 989/1810', 'Training loss: 1.5595', '23.7689 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 990/1810', 'Training loss: 1.5590', '20.4710 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 991/1810', 'Training loss: 1.5583', '20.7682 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 992/1810', 'Training loss: 1.5577', '22.6476 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 993/1810', 'Training loss: 1.5574', '20.5012 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 994/1810', 'Training loss: 1.5572', '20.7345 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 995/1810', 'Training loss: 1.5569', '27.7170 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 996/1810', 'Training loss: 1.5564', '21.6162 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 997/1810', 'Training loss: 1.5554', '20.3570 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 998/1810', 'Training loss: 1.5552', '20.5964 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 999/1810', 'Training loss: 1.5548', '23.4246 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1000/1810', 'Training loss: 1.5545', '20.2974 sec/batch')\n",
      "('Validation loss:', 1.4119051, 'Saving checkpoint!')\n",
      "('Epoch 6/10 ', 'Iteration 1001/1810', 'Training loss: 1.5552', '20.6514 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1002/1810', 'Training loss: 1.5548', '20.2125 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1003/1810', 'Training loss: 1.5545', '27.6084 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1004/1810', 'Training loss: 1.5540', '20.8417 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1005/1810', 'Training loss: 1.5538', '20.3290 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1006/1810', 'Training loss: 1.5530', '22.7359 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1007/1810', 'Training loss: 1.5524', '22.8497 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1008/1810', 'Training loss: 1.5517', '20.3864 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1009/1810', 'Training loss: 1.5511', '20.2549 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1010/1810', 'Training loss: 1.5510', '24.1604 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1011/1810', 'Training loss: 1.5505', '20.3501 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1012/1810', 'Training loss: 1.5500', '21.5545 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1013/1810', 'Training loss: 1.5498', '22.9488 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1014/1810', 'Training loss: 1.5494', '21.8701 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1015/1810', 'Training loss: 1.5490', '20.2015 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1016/1810', 'Training loss: 1.5486', '22.9961 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1017/1810', 'Training loss: 1.5485', '22.3896 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1018/1810', 'Training loss: 1.5484', '21.6154 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1019/1810', 'Training loss: 1.5481', '23.0139 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1020/1810', 'Training loss: 1.5478', '22.5499 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1021/1810', 'Training loss: 1.5472', '20.4815 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1022/1810', 'Training loss: 1.5469', '20.3265 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1023/1810', 'Training loss: 1.5464', '20.6269 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1024/1810', 'Training loss: 1.5461', '23.3621 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1025/1810', 'Training loss: 1.5457', '21.1597 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1026/1810', 'Training loss: 1.5453', '20.1324 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1027/1810', 'Training loss: 1.5450', '20.2487 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1028/1810', 'Training loss: 1.5446', '24.7283 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1029/1810', 'Training loss: 1.5446', '21.9145 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1030/1810', 'Training loss: 1.5441', '25.8835 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1031/1810', 'Training loss: 1.5436', '20.3949 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1032/1810', 'Training loss: 1.5431', '20.2912 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1033/1810', 'Training loss: 1.5429', '21.3664 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1034/1810', 'Training loss: 1.5426', '24.3599 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1035/1810', 'Training loss: 1.5423', '20.2536 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1036/1810', 'Training loss: 1.5421', '20.6344 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1037/1810', 'Training loss: 1.5419', '23.5342 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1038/1810', 'Training loss: 1.5416', '25.3835 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1039/1810', 'Training loss: 1.5411', '20.8613 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1040/1810', 'Training loss: 1.5408', '20.4200 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1041/1810', 'Training loss: 1.5407', '20.1770 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1042/1810', 'Training loss: 1.5403', '22.1899 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1043/1810', 'Training loss: 1.5403', '20.2927 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1044/1810', 'Training loss: 1.5402', '25.1298 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1045/1810', 'Training loss: 1.5399', '20.6480 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1046/1810', 'Training loss: 1.5398', '20.4536 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1047/1810', 'Training loss: 1.5396', '20.5174 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1048/1810', 'Training loss: 1.5393', '24.3143 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1049/1810', 'Training loss: 1.5392', '21.2303 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1050/1810', 'Training loss: 1.5391', '20.5749 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1051/1810', 'Training loss: 1.5388', '20.3310 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1052/1810', 'Training loss: 1.5387', '29.6475 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1053/1810', 'Training loss: 1.5385', '22.3032 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1054/1810', 'Training loss: 1.5385', '20.2781 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1055/1810', 'Training loss: 1.5381', '22.9515 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1056/1810', 'Training loss: 1.5380', '22.2002 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1057/1810', 'Training loss: 1.5379', '24.5983 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1058/1810', 'Training loss: 1.5380', '20.5032 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1059/1810', 'Training loss: 1.5378', '21.3536 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1060/1810', 'Training loss: 1.5374', '25.7159 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1061/1810', 'Training loss: 1.5373', '20.7294 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1062/1810', 'Training loss: 1.5369', '25.1853 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1063/1810', 'Training loss: 1.5369', '25.4236 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1064/1810', 'Training loss: 1.5366', '20.9329 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1065/1810', 'Training loss: 1.5365', '22.7060 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1066/1810', 'Training loss: 1.5363', '25.0131 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1067/1810', 'Training loss: 1.5361', '20.3006 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1068/1810', 'Training loss: 1.5357', '25.1901 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1069/1810', 'Training loss: 1.5354', '20.5108 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1070/1810', 'Training loss: 1.5351', '23.2024 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1071/1810', 'Training loss: 1.5350', '24.8862 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1072/1810', 'Training loss: 1.5350', '21.4334 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1073/1810', 'Training loss: 1.5348', '21.7257 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1074/1810', 'Training loss: 1.5345', '23.3790 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1075/1810', 'Training loss: 1.5345', '23.4813 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1076/1810', 'Training loss: 1.5344', '21.8058 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1077/1810', 'Training loss: 1.5345', '26.7238 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1078/1810', 'Training loss: 1.5344', '24.0221 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1079/1810', 'Training loss: 1.5341', '20.3050 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1080/1810', 'Training loss: 1.5339', '21.4457 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1081/1810', 'Training loss: 1.5335', '24.0637 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1082/1810', 'Training loss: 1.5332', '20.5919 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1083/1810', 'Training loss: 1.5332', '26.1244 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1084/1810', 'Training loss: 1.5330', '20.2196 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1085/1810', 'Training loss: 1.5330', '22.8227 sec/batch')\n",
      "('Epoch 6/10 ', 'Iteration 1086/1810', 'Training loss: 1.5327', '22.8323 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1087/1810', 'Training loss: 1.6254', '24.9547 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1088/1810', 'Training loss: 1.5608', '20.2789 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1089/1810', 'Training loss: 1.5396', '20.6731 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1090/1810', 'Training loss: 1.5345', '25.3013 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1091/1810', 'Training loss: 1.5309', '21.9718 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1092/1810', 'Training loss: 1.5281', '26.8040 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1093/1810', 'Training loss: 1.5209', '23.0756 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1094/1810', 'Training loss: 1.5175', '20.4232 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1095/1810', 'Training loss: 1.5141', '22.7074 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1096/1810', 'Training loss: 1.5100', '23.9544 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1097/1810', 'Training loss: 1.5117', '20.3283 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1098/1810', 'Training loss: 1.5086', '24.5152 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1099/1810', 'Training loss: 1.5073', '23.1833 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1100/1810', 'Training loss: 1.5058', '20.3011 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1101/1810', 'Training loss: 1.5073', '25.5018 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1102/1810', 'Training loss: 1.5035', '20.4330 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1103/1810', 'Training loss: 1.5016', '24.3791 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1104/1810', 'Training loss: 1.5017', '21.2944 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1105/1810', 'Training loss: 1.5017', '23.1811 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1106/1810', 'Training loss: 1.5027', '26.4849 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1107/1810', 'Training loss: 1.5023', '22.8367 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1108/1810', 'Training loss: 1.5011', '22.1020 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1109/1810', 'Training loss: 1.5001', '23.6197 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1110/1810', 'Training loss: 1.4998', '23.8407 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1111/1810', 'Training loss: 1.4987', '20.5049 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1112/1810', 'Training loss: 1.4982', '23.3128 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1113/1810', 'Training loss: 1.4982', '23.3618 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1114/1810', 'Training loss: 1.4957', '23.0293 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1115/1810', 'Training loss: 1.4952', '20.3637 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1116/1810', 'Training loss: 1.4949', '25.9497 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1117/1810', 'Training loss: 1.4945', '20.3690 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1118/1810', 'Training loss: 1.4947', '23.4842 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1119/1810', 'Training loss: 1.4946', '23.3360 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1120/1810', 'Training loss: 1.4943', '24.9370 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1121/1810', 'Training loss: 1.4945', '20.4429 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1122/1810', 'Training loss: 1.4951', '22.8435 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1123/1810', 'Training loss: 1.4949', '23.1929 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1124/1810', 'Training loss: 1.4935', '21.0955 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1125/1810', 'Training loss: 1.4923', '24.7201 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1126/1810', 'Training loss: 1.4911', '23.0331 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1127/1810', 'Training loss: 1.4899', '20.4310 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1128/1810', 'Training loss: 1.4891', '24.5178 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1129/1810', 'Training loss: 1.4885', '23.6746 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1130/1810', 'Training loss: 1.4879', '20.4379 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1131/1810', 'Training loss: 1.4879', '21.7705 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1132/1810', 'Training loss: 1.4874', '24.0812 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1133/1810', 'Training loss: 1.4862', '20.1667 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1134/1810', 'Training loss: 1.4856', '23.1224 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1135/1810', 'Training loss: 1.4854', '25.8425 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1136/1810', 'Training loss: 1.4851', '23.9650 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1137/1810', 'Training loss: 1.4847', '23.7707 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1138/1810', 'Training loss: 1.4839', '21.2745 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1139/1810', 'Training loss: 1.4840', '22.4545 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1140/1810', 'Training loss: 1.4837', '23.5590 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1141/1810', 'Training loss: 1.4835', '25.7356 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1142/1810', 'Training loss: 1.4839', '20.1967 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1143/1810', 'Training loss: 1.4836', '24.1600 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1144/1810', 'Training loss: 1.4836', '22.4671 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1145/1810', 'Training loss: 1.4833', '25.2520 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1146/1810', 'Training loss: 1.4830', '24.0537 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1147/1810', 'Training loss: 1.4833', '19.0814 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1148/1810', 'Training loss: 1.4829', '20.0881 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1149/1810', 'Training loss: 1.4829', '25.1911 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1150/1810', 'Training loss: 1.4827', '22.4286 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1151/1810', 'Training loss: 1.4832', '20.4701 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1152/1810', 'Training loss: 1.4839', '20.5482 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1153/1810', 'Training loss: 1.4833', '22.8607 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1154/1810', 'Training loss: 1.4836', '20.3949 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1155/1810', 'Training loss: 1.4829', '20.2025 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1156/1810', 'Training loss: 1.4827', '24.0479 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1157/1810', 'Training loss: 1.4826', '20.2359 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1158/1810', 'Training loss: 1.4823', '20.3129 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1159/1810', 'Training loss: 1.4823', '20.3947 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1160/1810', 'Training loss: 1.4826', '20.2142 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1161/1810', 'Training loss: 1.4827', '24.3250 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1162/1810', 'Training loss: 1.4825', '20.7845 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1163/1810', 'Training loss: 1.4827', '20.2806 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1164/1810', 'Training loss: 1.4823', '21.1740 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1165/1810', 'Training loss: 1.4819', '20.9853 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1166/1810', 'Training loss: 1.4819', '23.5277 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1167/1810', 'Training loss: 1.4818', '20.1022 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1168/1810', 'Training loss: 1.4814', '23.2756 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1169/1810', 'Training loss: 1.4812', '20.3759 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1170/1810', 'Training loss: 1.4807', '20.1369 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1171/1810', 'Training loss: 1.4802', '21.0105 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1172/1810', 'Training loss: 1.4796', '24.6514 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1173/1810', 'Training loss: 1.4791', '20.3855 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1174/1810', 'Training loss: 1.4790', '19.6051 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1175/1810', 'Training loss: 1.4788', '25.0313 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1176/1810', 'Training loss: 1.4786', '20.3235 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1177/1810', 'Training loss: 1.4782', '20.2700 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1178/1810', 'Training loss: 1.4774', '20.2962 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1179/1810', 'Training loss: 1.4774', '20.7479 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1180/1810', 'Training loss: 1.4770', '26.2393 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1181/1810', 'Training loss: 1.4767', '20.7200 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1182/1810', 'Training loss: 1.4764', '20.3998 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1183/1810', 'Training loss: 1.4762', '20.4239 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1184/1810', 'Training loss: 1.4759', '24.9911 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1185/1810', 'Training loss: 1.4754', '20.7620 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1186/1810', 'Training loss: 1.4753', '20.3219 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1187/1810', 'Training loss: 1.4746', '20.2689 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1188/1810', 'Training loss: 1.4741', '22.9944 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1189/1810', 'Training loss: 1.4735', '20.2646 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1190/1810', 'Training loss: 1.4729', '20.7482 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1191/1810', 'Training loss: 1.4728', '23.7118 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1192/1810', 'Training loss: 1.4723', '19.9721 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1193/1810', 'Training loss: 1.4720', '19.5369 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1194/1810', 'Training loss: 1.4719', '24.9872 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1195/1810', 'Training loss: 1.4716', '21.2936 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1196/1810', 'Training loss: 1.4713', '20.8750 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1197/1810', 'Training loss: 1.4709', '20.3723 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1198/1810', 'Training loss: 1.4710', '20.3771 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1199/1810', 'Training loss: 1.4708', '23.9259 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1200/1810', 'Training loss: 1.4706', '20.3174 sec/batch')\n",
      "('Validation loss:', 1.3365016, 'Saving checkpoint!')\n",
      "('Epoch 7/10 ', 'Iteration 1201/1810', 'Training loss: 1.4717', '20.3302 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1202/1810', 'Training loss: 1.4713', '20.3422 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1203/1810', 'Training loss: 1.4711', '20.3716 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1204/1810', 'Training loss: 1.4707', '25.1344 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1205/1810', 'Training loss: 1.4704', '20.3717 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1206/1810', 'Training loss: 1.4702', '24.0173 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1207/1810', 'Training loss: 1.4699', '20.2897 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1208/1810', 'Training loss: 1.4697', '20.3740 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1209/1810', 'Training loss: 1.4694', '20.3581 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1210/1810', 'Training loss: 1.4694', '20.3640 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1211/1810', 'Training loss: 1.4690', '23.0088 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1212/1810', 'Training loss: 1.4685', '22.7440 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1213/1810', 'Training loss: 1.4680', '20.1278 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1214/1810', 'Training loss: 1.4678', '20.3487 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1215/1810', 'Training loss: 1.4676', '20.2649 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1216/1810', 'Training loss: 1.4674', '23.8951 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1217/1810', 'Training loss: 1.4672', '20.7579 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1218/1810', 'Training loss: 1.4670', '19.4142 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1219/1810', 'Training loss: 1.4668', '26.0159 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1220/1810', 'Training loss: 1.4663', '22.4537 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1221/1810', 'Training loss: 1.4660', '20.2373 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1222/1810', 'Training loss: 1.4660', '20.0735 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1223/1810', 'Training loss: 1.4657', '20.6672 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1224/1810', 'Training loss: 1.4656', '20.3880 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1225/1810', 'Training loss: 1.4656', '20.5799 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1226/1810', 'Training loss: 1.4654', '22.4714 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1227/1810', 'Training loss: 1.4653', '20.3658 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1228/1810', 'Training loss: 1.4652', '20.6567 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1229/1810', 'Training loss: 1.4651', '20.6195 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1230/1810', 'Training loss: 1.4650', '23.1171 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1231/1810', 'Training loss: 1.4650', '20.3615 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1232/1810', 'Training loss: 1.4648', '20.2641 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1233/1810', 'Training loss: 1.4647', '20.3298 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1234/1810', 'Training loss: 1.4646', '23.3733 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1235/1810', 'Training loss: 1.4647', '21.7506 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1236/1810', 'Training loss: 1.4644', '22.4238 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1237/1810', 'Training loss: 1.4643', '20.2831 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1238/1810', 'Training loss: 1.4643', '20.2857 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1239/1810', 'Training loss: 1.4644', '22.6240 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1240/1810', 'Training loss: 1.4643', '20.5392 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1241/1810', 'Training loss: 1.4639', '20.4149 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1242/1810', 'Training loss: 1.4638', '20.1936 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1243/1810', 'Training loss: 1.4636', '20.4270 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1244/1810', 'Training loss: 1.4636', '23.3566 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1245/1810', 'Training loss: 1.4634', '20.4564 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1246/1810', 'Training loss: 1.4633', '19.1960 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1247/1810', 'Training loss: 1.4632', '23.7169 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1248/1810', 'Training loss: 1.4630', '21.0108 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1249/1810', 'Training loss: 1.4626', '20.3348 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1250/1810', 'Training loss: 1.4623', '21.5625 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1251/1810', 'Training loss: 1.4622', '24.1822 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1252/1810', 'Training loss: 1.4621', '19.8064 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1253/1810', 'Training loss: 1.4622', '19.9230 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1254/1810', 'Training loss: 1.4620', '20.2806 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1255/1810', 'Training loss: 1.4618', '22.6353 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1256/1810', 'Training loss: 1.4618', '20.4246 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1257/1810', 'Training loss: 1.4618', '19.8453 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1258/1810', 'Training loss: 1.4620', '22.6146 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1259/1810', 'Training loss: 1.4620', '20.6051 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1260/1810', 'Training loss: 1.4618', '20.2189 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1261/1810', 'Training loss: 1.4617', '22.0479 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1262/1810', 'Training loss: 1.4614', '20.2785 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1263/1810', 'Training loss: 1.4612', '19.6335 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1264/1810', 'Training loss: 1.4611', '21.7305 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1265/1810', 'Training loss: 1.4610', '24.6902 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1266/1810', 'Training loss: 1.4611', '29.2480 sec/batch')\n",
      "('Epoch 7/10 ', 'Iteration 1267/1810', 'Training loss: 1.4608', '19.3756 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1268/1810', 'Training loss: 1.5605', '19.6787 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1269/1810', 'Training loss: 1.5033', '20.2206 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1270/1810', 'Training loss: 1.4851', '23.2014 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1271/1810', 'Training loss: 1.4783', '20.4506 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1272/1810', 'Training loss: 1.4757', '20.2505 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1273/1810', 'Training loss: 1.4711', '22.4402 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1274/1810', 'Training loss: 1.4627', '20.7855 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1275/1810', 'Training loss: 1.4605', '20.3123 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1276/1810', 'Training loss: 1.4573', '18.9606 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1277/1810', 'Training loss: 1.4522', '26.4386 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1278/1810', 'Training loss: 1.4539', '22.3808 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1279/1810', 'Training loss: 1.4501', '23.5305 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1280/1810', 'Training loss: 1.4495', '20.3152 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1281/1810', 'Training loss: 1.4477', '23.1143 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1282/1810', 'Training loss: 1.4491', '24.7377 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1283/1810', 'Training loss: 1.4457', '20.2296 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1284/1810', 'Training loss: 1.4434', '20.2890 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1285/1810', 'Training loss: 1.4437', '21.1470 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1286/1810', 'Training loss: 1.4439', '23.0060 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1287/1810', 'Training loss: 1.4449', '20.3908 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1288/1810', 'Training loss: 1.4442', '20.1841 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1289/1810', 'Training loss: 1.4429', '23.0232 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1290/1810', 'Training loss: 1.4421', '21.3476 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1291/1810', 'Training loss: 1.4417', '19.1880 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1292/1810', 'Training loss: 1.4407', '22.6279 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1293/1810', 'Training loss: 1.4400', '21.7030 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1294/1810', 'Training loss: 1.4401', '19.3238 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1295/1810', 'Training loss: 1.4375', '24.0283 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1296/1810', 'Training loss: 1.4371', '21.7747 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1297/1810', 'Training loss: 1.4368', '20.2850 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1298/1810', 'Training loss: 1.4361', '20.2700 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1299/1810', 'Training loss: 1.4364', '20.5104 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1300/1810', 'Training loss: 1.4360', '20.3882 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1301/1810', 'Training loss: 1.4352', '22.2204 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1302/1810', 'Training loss: 1.4351', '20.6720 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1303/1810', 'Training loss: 1.4356', '20.2771 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1304/1810', 'Training loss: 1.4350', '21.8459 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1305/1810', 'Training loss: 1.4336', '21.8669 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1306/1810', 'Training loss: 1.4324', '20.5465 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1307/1810', 'Training loss: 1.4310', '19.4267 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1308/1810', 'Training loss: 1.4299', '22.8061 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1309/1810', 'Training loss: 1.4294', '22.7047 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1310/1810', 'Training loss: 1.4285', '18.9856 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1311/1810', 'Training loss: 1.4279', '21.3017 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1312/1810', 'Training loss: 1.4281', '26.5075 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1313/1810', 'Training loss: 1.4279', '21.1083 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1314/1810', 'Training loss: 1.4269', '20.3567 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1315/1810', 'Training loss: 1.4265', '20.6352 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1316/1810', 'Training loss: 1.4263', '23.0328 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1317/1810', 'Training loss: 1.4261', '20.2138 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1318/1810', 'Training loss: 1.4258', '20.5001 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1319/1810', 'Training loss: 1.4251', '24.2912 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1320/1810', 'Training loss: 1.4251', '20.2145 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1321/1810', 'Training loss: 1.4248', '20.1889 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1322/1810', 'Training loss: 1.4247', '20.1496 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1323/1810', 'Training loss: 1.4251', '22.3825 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1324/1810', 'Training loss: 1.4251', '21.5744 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1325/1810', 'Training loss: 1.4251', '20.1884 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1326/1810', 'Training loss: 1.4249', '22.5838 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1327/1810', 'Training loss: 1.4247', '22.6007 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1328/1810', 'Training loss: 1.4248', '20.5057 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1329/1810', 'Training loss: 1.4243', '22.1290 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1330/1810', 'Training loss: 1.4242', '20.9100 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1331/1810', 'Training loss: 1.4240', '20.2679 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1332/1810', 'Training loss: 1.4245', '20.5456 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1333/1810', 'Training loss: 1.4252', '20.4417 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1334/1810', 'Training loss: 1.4246', '21.9057 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1335/1810', 'Training loss: 1.4248', '22.1538 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1336/1810', 'Training loss: 1.4241', '23.1919 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1337/1810', 'Training loss: 1.4241', '22.9991 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1338/1810', 'Training loss: 1.4240', '19.1740 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1339/1810', 'Training loss: 1.4238', '21.2179 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1340/1810', 'Training loss: 1.4238', '23.7770 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1341/1810', 'Training loss: 1.4241', '20.8452 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1342/1810', 'Training loss: 1.4241', '21.3213 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1343/1810', 'Training loss: 1.4240', '25.3956 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1344/1810', 'Training loss: 1.4241', '20.1998 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1345/1810', 'Training loss: 1.4237', '20.8084 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1346/1810', 'Training loss: 1.4232', '23.0033 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1347/1810', 'Training loss: 1.4232', '20.8893 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1348/1810', 'Training loss: 1.4231', '20.2153 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1349/1810', 'Training loss: 1.4227', '24.0322 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1350/1810', 'Training loss: 1.4225', '20.3720 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1351/1810', 'Training loss: 1.4220', '20.3068 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1352/1810', 'Training loss: 1.4216', '21.4050 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1353/1810', 'Training loss: 1.4211', '23.1945 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1354/1810', 'Training loss: 1.4206', '20.6719 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1355/1810', 'Training loss: 1.4205', '19.3633 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1356/1810', 'Training loss: 1.4204', '25.1776 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1357/1810', 'Training loss: 1.4203', '20.3216 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1358/1810', 'Training loss: 1.4200', '22.7541 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1359/1810', 'Training loss: 1.4192', '23.4957 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1360/1810', 'Training loss: 1.4192', '20.2254 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1361/1810', 'Training loss: 1.4188', '22.3336 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1362/1810', 'Training loss: 1.4186', '20.9539 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1363/1810', 'Training loss: 1.4185', '20.6817 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1364/1810', 'Training loss: 1.4183', '23.9169 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1365/1810', 'Training loss: 1.4181', '21.1404 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1366/1810', 'Training loss: 1.4177', '22.2330 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1367/1810', 'Training loss: 1.4176', '20.3093 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1368/1810', 'Training loss: 1.4170', '20.3636 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1369/1810', 'Training loss: 1.4166', '22.9540 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1370/1810', 'Training loss: 1.4161', '20.4847 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1371/1810', 'Training loss: 1.4156', '20.1878 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1372/1810', 'Training loss: 1.4156', '22.6716 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1373/1810', 'Training loss: 1.4151', '21.3232 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1374/1810', 'Training loss: 1.4148', '21.8885 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1375/1810', 'Training loss: 1.4149', '22.7917 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1376/1810', 'Training loss: 1.4147', '20.2956 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1377/1810', 'Training loss: 1.4144', '19.6652 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1378/1810', 'Training loss: 1.4141', '25.0990 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1379/1810', 'Training loss: 1.4142', '20.5753 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1380/1810', 'Training loss: 1.4142', '19.5513 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1381/1810', 'Training loss: 1.4141', '24.8230 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1382/1810', 'Training loss: 1.4139', '21.0142 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1383/1810', 'Training loss: 1.4136', '18.9109 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1384/1810', 'Training loss: 1.4134', '24.0691 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1385/1810', 'Training loss: 1.4131', '20.2956 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1386/1810', 'Training loss: 1.4129', '20.9544 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1387/1810', 'Training loss: 1.4126', '24.1825 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1388/1810', 'Training loss: 1.4123', '21.9710 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1389/1810', 'Training loss: 1.4122', '19.7132 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1390/1810', 'Training loss: 1.4119', '20.1658 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1391/1810', 'Training loss: 1.4119', '25.3169 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1392/1810', 'Training loss: 1.4115', '20.2317 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1393/1810', 'Training loss: 1.4111', '19.3001 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1394/1810', 'Training loss: 1.4106', '22.0099 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1395/1810', 'Training loss: 1.4104', '23.0227 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1396/1810', 'Training loss: 1.4103', '19.5562 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1397/1810', 'Training loss: 1.4100', '22.3662 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1398/1810', 'Training loss: 1.4097', '23.2162 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1399/1810', 'Training loss: 1.4096', '22.8260 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1400/1810', 'Training loss: 1.4093', '19.1910 sec/batch')\n",
      "('Validation loss:', 1.2845649, 'Saving checkpoint!')\n",
      "('Epoch 8/10 ', 'Iteration 1401/1810', 'Training loss: 1.4100', '18.2136 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1402/1810', 'Training loss: 1.4097', '22.8353 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1403/1810', 'Training loss: 1.4097', '23.2935 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1404/1810', 'Training loss: 1.4095', '20.4649 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1405/1810', 'Training loss: 1.4095', '20.5234 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1406/1810', 'Training loss: 1.4096', '23.7548 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1407/1810', 'Training loss: 1.4094', '21.7487 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1408/1810', 'Training loss: 1.4094', '20.5501 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1409/1810', 'Training loss: 1.4093', '20.5012 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1410/1810', 'Training loss: 1.4092', '22.8247 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1411/1810', 'Training loss: 1.4092', '20.3518 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1412/1810', 'Training loss: 1.4091', '24.2809 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1413/1810', 'Training loss: 1.4091', '23.6352 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1414/1810', 'Training loss: 1.4090', '20.1955 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1415/1810', 'Training loss: 1.4089', '19.5405 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1416/1810', 'Training loss: 1.4090', '23.3140 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1417/1810', 'Training loss: 1.4088', '21.6470 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1418/1810', 'Training loss: 1.4088', '20.8589 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1419/1810', 'Training loss: 1.4088', '22.2421 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1420/1810', 'Training loss: 1.4089', '21.6528 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1421/1810', 'Training loss: 1.4089', '20.2483 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1422/1810', 'Training loss: 1.4086', '20.4396 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1423/1810', 'Training loss: 1.4084', '20.4238 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1424/1810', 'Training loss: 1.4081', '26.5170 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1425/1810', 'Training loss: 1.4081', '24.1016 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1426/1810', 'Training loss: 1.4079', '20.1456 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1427/1810', 'Training loss: 1.4079', '21.6356 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1428/1810', 'Training loss: 1.4079', '24.8008 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1429/1810', 'Training loss: 1.4077', '20.8697 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1430/1810', 'Training loss: 1.4074', '20.4542 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1431/1810', 'Training loss: 1.4071', '20.4133 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1432/1810', 'Training loss: 1.4070', '23.0230 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1433/1810', 'Training loss: 1.4070', '20.3044 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1434/1810', 'Training loss: 1.4071', '23.4362 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1435/1810', 'Training loss: 1.4069', '21.5523 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1436/1810', 'Training loss: 1.4067', '19.4228 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1437/1810', 'Training loss: 1.4070', '23.5698 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1438/1810', 'Training loss: 1.4069', '22.7730 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1439/1810', 'Training loss: 1.4071', '20.2891 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1440/1810', 'Training loss: 1.4071', '20.9332 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1441/1810', 'Training loss: 1.4070', '20.6175 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1442/1810', 'Training loss: 1.4069', '23.7930 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1443/1810', 'Training loss: 1.4067', '23.9199 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1444/1810', 'Training loss: 1.4065', '20.3786 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1445/1810', 'Training loss: 1.4066', '20.6933 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1446/1810', 'Training loss: 1.4065', '20.8008 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1447/1810', 'Training loss: 1.4065', '26.3878 sec/batch')\n",
      "('Epoch 8/10 ', 'Iteration 1448/1810', 'Training loss: 1.4064', '20.3274 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1449/1810', 'Training loss: 1.5113', '19.2764 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1450/1810', 'Training loss: 1.4539', '24.3896 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1451/1810', 'Training loss: 1.4346', '21.7722 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1452/1810', 'Training loss: 1.4276', '19.0428 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1453/1810', 'Training loss: 1.4211', '23.1496 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1454/1810', 'Training loss: 1.4169', '21.2867 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1455/1810', 'Training loss: 1.4110', '20.3850 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1456/1810', 'Training loss: 1.4089', '20.4788 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1457/1810', 'Training loss: 1.4056', '24.8891 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1458/1810', 'Training loss: 1.4006', '20.4970 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1459/1810', 'Training loss: 1.4021', '23.6967 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1460/1810', 'Training loss: 1.3987', '20.4858 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1461/1810', 'Training loss: 1.3983', '20.2353 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1462/1810', 'Training loss: 1.3972', '20.5492 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1463/1810', 'Training loss: 1.3987', '24.3816 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1464/1810', 'Training loss: 1.3953', '20.6452 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1465/1810', 'Training loss: 1.3934', '23.7034 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1466/1810', 'Training loss: 1.3938', '20.3336 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1467/1810', 'Training loss: 1.3935', '19.6826 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1468/1810', 'Training loss: 1.3948', '21.6728 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1469/1810', 'Training loss: 1.3939', '23.5562 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1470/1810', 'Training loss: 1.3929', '20.4262 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1471/1810', 'Training loss: 1.3918', '20.2734 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1472/1810', 'Training loss: 1.3917', '23.2231 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1473/1810', 'Training loss: 1.3907', '23.9443 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1474/1810', 'Training loss: 1.3902', '20.9094 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1475/1810', 'Training loss: 1.3903', '21.9648 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1476/1810', 'Training loss: 1.3881', '22.7227 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1477/1810', 'Training loss: 1.3878', '20.0503 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1478/1810', 'Training loss: 1.3872', '19.3669 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1479/1810', 'Training loss: 1.3871', '23.9250 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1480/1810', 'Training loss: 1.3874', '20.4177 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1481/1810', 'Training loss: 1.3873', '22.9400 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1482/1810', 'Training loss: 1.3869', '22.6091 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1483/1810', 'Training loss: 1.3865', '19.1213 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1484/1810', 'Training loss: 1.3872', '22.0457 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1485/1810', 'Training loss: 1.3869', '22.8766 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1486/1810', 'Training loss: 1.3856', '20.4987 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1487/1810', 'Training loss: 1.3843', '22.4742 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1488/1810', 'Training loss: 1.3832', '22.9196 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1489/1810', 'Training loss: 1.3821', '20.0298 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1490/1810', 'Training loss: 1.3817', '22.0083 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1491/1810', 'Training loss: 1.3811', '22.4584 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1492/1810', 'Training loss: 1.3804', '20.3526 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1493/1810', 'Training loss: 1.3808', '20.3589 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1494/1810', 'Training loss: 1.3805', '23.1272 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1495/1810', 'Training loss: 1.3794', '21.5380 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1496/1810', 'Training loss: 1.3789', '19.7350 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1497/1810', 'Training loss: 1.3787', '22.0982 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1498/1810', 'Training loss: 1.3789', '22.9411 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1499/1810', 'Training loss: 1.3785', '20.5638 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1500/1810', 'Training loss: 1.3779', '20.4694 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1501/1810', 'Training loss: 1.3778', '23.7333 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1502/1810', 'Training loss: 1.3776', '20.6411 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1503/1810', 'Training loss: 1.3775', '23.1738 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1504/1810', 'Training loss: 1.3778', '24.0087 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1505/1810', 'Training loss: 1.3777', '20.0415 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1506/1810', 'Training loss: 1.3776', '19.1994 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1507/1810', 'Training loss: 1.3774', '23.7540 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1508/1810', 'Training loss: 1.3773', '22.1546 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1509/1810', 'Training loss: 1.3775', '20.6625 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1510/1810', 'Training loss: 1.3772', '26.6769 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1511/1810', 'Training loss: 1.3771', '21.4531 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1512/1810', 'Training loss: 1.3772', '18.8884 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1513/1810', 'Training loss: 1.3778', '23.6108 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1514/1810', 'Training loss: 1.3785', '21.1749 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1515/1810', 'Training loss: 1.3779', '20.3668 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1516/1810', 'Training loss: 1.3780', '21.6898 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1517/1810', 'Training loss: 1.3775', '21.7341 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1518/1810', 'Training loss: 1.3774', '21.7399 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1519/1810', 'Training loss: 1.3772', '21.6699 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1520/1810', 'Training loss: 1.3772', '23.4008 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1521/1810', 'Training loss: 1.3772', '20.2964 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1522/1810', 'Training loss: 1.3777', '20.2788 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1523/1810', 'Training loss: 1.3777', '22.2600 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1524/1810', 'Training loss: 1.3776', '21.7375 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1525/1810', 'Training loss: 1.3778', '20.3452 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1526/1810', 'Training loss: 1.3776', '23.4469 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1527/1810', 'Training loss: 1.3772', '20.3720 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1528/1810', 'Training loss: 1.3774', '23.1365 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1529/1810', 'Training loss: 1.3773', '25.6045 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1530/1810', 'Training loss: 1.3770', '20.2498 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1531/1810', 'Training loss: 1.3768', '19.6211 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1532/1810', 'Training loss: 1.3766', '21.2375 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1533/1810', 'Training loss: 1.3762', '24.0558 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1534/1810', 'Training loss: 1.3757', '24.1472 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1535/1810', 'Training loss: 1.3752', '20.7778 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1536/1810', 'Training loss: 1.3751', '20.4512 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1537/1810', 'Training loss: 1.3751', '20.2643 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1538/1810', 'Training loss: 1.3749', '24.6132 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1539/1810', 'Training loss: 1.3747', '20.4264 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1540/1810', 'Training loss: 1.3740', '19.6232 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1541/1810', 'Training loss: 1.3740', '22.9462 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1542/1810', 'Training loss: 1.3736', '22.6345 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1543/1810', 'Training loss: 1.3734', '20.3969 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1544/1810', 'Training loss: 1.3732', '20.3795 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1545/1810', 'Training loss: 1.3730', '23.2676 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1546/1810', 'Training loss: 1.3728', '20.7098 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1547/1810', 'Training loss: 1.3724', '24.6780 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1548/1810', 'Training loss: 1.3723', '21.2958 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1549/1810', 'Training loss: 1.3718', '20.6593 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1550/1810', 'Training loss: 1.3714', '23.4163 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1551/1810', 'Training loss: 1.3709', '22.6652 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1552/1810', 'Training loss: 1.3705', '19.5020 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1553/1810', 'Training loss: 1.3704', '20.6264 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1554/1810', 'Training loss: 1.3700', '24.6003 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1555/1810', 'Training loss: 1.3697', '20.5864 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1556/1810', 'Training loss: 1.3698', '20.2464 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1557/1810', 'Training loss: 1.3695', '21.3773 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1558/1810', 'Training loss: 1.3693', '22.8300 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1559/1810', 'Training loss: 1.3691', '20.3584 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1560/1810', 'Training loss: 1.3692', '23.5292 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1561/1810', 'Training loss: 1.3693', '21.4617 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1562/1810', 'Training loss: 1.3691', '19.3953 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1563/1810', 'Training loss: 1.3689', '22.5912 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1564/1810', 'Training loss: 1.3685', '24.4165 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1565/1810', 'Training loss: 1.3684', '20.5165 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1566/1810', 'Training loss: 1.3680', '22.3428 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1567/1810', 'Training loss: 1.3678', '21.6213 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1568/1810', 'Training loss: 1.3675', '20.9637 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1569/1810', 'Training loss: 1.3672', '23.3713 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1570/1810', 'Training loss: 1.3671', '23.2242 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1571/1810', 'Training loss: 1.3670', '19.2485 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1572/1810', 'Training loss: 1.3671', '21.9108 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1573/1810', 'Training loss: 1.3667', '22.9388 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1574/1810', 'Training loss: 1.3663', '20.7701 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1575/1810', 'Training loss: 1.3658', '23.3441 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1576/1810', 'Training loss: 1.3658', '21.1675 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1577/1810', 'Training loss: 1.3656', '20.3711 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1578/1810', 'Training loss: 1.3655', '20.3980 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1579/1810', 'Training loss: 1.3652', '26.8618 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1580/1810', 'Training loss: 1.3650', '22.6498 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1581/1810', 'Training loss: 1.3648', '19.6990 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1582/1810', 'Training loss: 1.3644', '20.1443 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1583/1810', 'Training loss: 1.3641', '23.0392 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1584/1810', 'Training loss: 1.3640', '20.2627 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1585/1810', 'Training loss: 1.3637', '24.4044 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1586/1810', 'Training loss: 1.3638', '22.0272 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1587/1810', 'Training loss: 1.3639', '18.8991 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1588/1810', 'Training loss: 1.3637', '23.7236 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1589/1810', 'Training loss: 1.3637', '23.8403 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1590/1810', 'Training loss: 1.3636', '19.6931 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1591/1810', 'Training loss: 1.3636', '21.4452 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1592/1810', 'Training loss: 1.3637', '23.7713 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1593/1810', 'Training loss: 1.3637', '20.5441 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1594/1810', 'Training loss: 1.3635', '24.8409 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1595/1810', 'Training loss: 1.3635', '21.8042 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1596/1810', 'Training loss: 1.3635', '20.8562 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1597/1810', 'Training loss: 1.3636', '20.3344 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1598/1810', 'Training loss: 1.3634', '20.4704 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1599/1810', 'Training loss: 1.3634', '23.8922 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1600/1810', 'Training loss: 1.3634', '21.0375 sec/batch')\n",
      "('Validation loss:', 1.2472697, 'Saving checkpoint!')\n",
      "('Epoch 9/10 ', 'Iteration 1601/1810', 'Training loss: 1.3645', '20.4288 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1602/1810', 'Training loss: 1.3646', '29.5386 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1603/1810', 'Training loss: 1.3643', '23.9287 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1604/1810', 'Training loss: 1.3642', '18.9380 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1605/1810', 'Training loss: 1.3640', '24.1582 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1606/1810', 'Training loss: 1.3640', '22.5945 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1607/1810', 'Training loss: 1.3639', '21.8704 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1608/1810', 'Training loss: 1.3640', '23.0173 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1609/1810', 'Training loss: 1.3640', '23.1215 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1610/1810', 'Training loss: 1.3640', '20.9009 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1611/1810', 'Training loss: 1.3637', '23.5341 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1612/1810', 'Training loss: 1.3635', '21.3411 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1613/1810', 'Training loss: 1.3634', '20.5209 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1614/1810', 'Training loss: 1.3635', '22.8133 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1615/1810', 'Training loss: 1.3636', '21.0768 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1616/1810', 'Training loss: 1.3635', '24.0868 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1617/1810', 'Training loss: 1.3634', '22.1582 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1618/1810', 'Training loss: 1.3636', '22.1831 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1619/1810', 'Training loss: 1.3637', '20.3758 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1620/1810', 'Training loss: 1.3639', '24.2791 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1621/1810', 'Training loss: 1.3639', '20.9369 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1622/1810', 'Training loss: 1.3638', '23.1963 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1623/1810', 'Training loss: 1.3638', '20.2675 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1624/1810', 'Training loss: 1.3636', '23.7100 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1625/1810', 'Training loss: 1.3634', '20.4166 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1626/1810', 'Training loss: 1.3634', '23.3122 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1627/1810', 'Training loss: 1.3634', '20.6801 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1628/1810', 'Training loss: 1.3635', '25.1913 sec/batch')\n",
      "('Epoch 9/10 ', 'Iteration 1629/1810', 'Training loss: 1.3633', '20.4736 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1630/1810', 'Training loss: 1.4659', '22.9575 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1631/1810', 'Training loss: 1.4129', '24.4392 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1632/1810', 'Training loss: 1.3920', '23.9117 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1633/1810', 'Training loss: 1.3892', '20.3968 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1634/1810', 'Training loss: 1.3880', '22.6343 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1635/1810', 'Training loss: 1.3839', '22.5875 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1636/1810', 'Training loss: 1.3780', '23.1235 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1637/1810', 'Training loss: 1.3772', '23.0825 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1638/1810', 'Training loss: 1.3728', '20.3182 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1639/1810', 'Training loss: 1.3668', '20.3659 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1640/1810', 'Training loss: 1.3685', '23.1421 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1641/1810', 'Training loss: 1.3654', '20.0946 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1642/1810', 'Training loss: 1.3645', '23.5024 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1643/1810', 'Training loss: 1.3630', '23.6366 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1644/1810', 'Training loss: 1.3640', '20.6687 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1645/1810', 'Training loss: 1.3605', '22.5608 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1646/1810', 'Training loss: 1.3580', '26.3125 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1647/1810', 'Training loss: 1.3583', '20.4578 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1648/1810', 'Training loss: 1.3583', '21.8959 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1649/1810', 'Training loss: 1.3593', '25.3711 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1650/1810', 'Training loss: 1.3583', '20.1300 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1651/1810', 'Training loss: 1.3572', '21.0060 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1652/1810', 'Training loss: 1.3565', '24.3099 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1653/1810', 'Training loss: 1.3566', '20.4342 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1654/1810', 'Training loss: 1.3557', '22.3214 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1655/1810', 'Training loss: 1.3554', '25.4838 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1656/1810', 'Training loss: 1.3554', '20.6559 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1657/1810', 'Training loss: 1.3531', '22.6120 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1658/1810', 'Training loss: 1.3525', '23.2230 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1659/1810', 'Training loss: 1.3519', '20.9643 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1660/1810', 'Training loss: 1.3516', '21.5625 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1661/1810', 'Training loss: 1.3518', '27.8866 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1662/1810', 'Training loss: 1.3519', '20.2704 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1663/1810', 'Training loss: 1.3515', '20.5088 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1664/1810', 'Training loss: 1.3511', '24.6451 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1665/1810', 'Training loss: 1.3515', '23.5151 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1666/1810', 'Training loss: 1.3513', '20.4766 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1667/1810', 'Training loss: 1.3501', '21.0291 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1668/1810', 'Training loss: 1.3492', '22.7593 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1669/1810', 'Training loss: 1.3478', '22.1615 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1670/1810', 'Training loss: 1.3468', '24.0309 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1671/1810', 'Training loss: 1.3463', '20.4316 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1672/1810', 'Training loss: 1.3456', '20.3079 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1673/1810', 'Training loss: 1.3451', '25.1774 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1674/1810', 'Training loss: 1.3453', '20.3490 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1675/1810', 'Training loss: 1.3450', '22.5822 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1676/1810', 'Training loss: 1.3441', '28.7379 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1677/1810', 'Training loss: 1.3436', '21.7720 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1678/1810', 'Training loss: 1.3434', '19.1315 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1679/1810', 'Training loss: 1.3433', '24.0965 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1680/1810', 'Training loss: 1.3427', '22.8629 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1681/1810', 'Training loss: 1.3420', '25.1189 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1682/1810', 'Training loss: 1.3422', '23.2073 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1683/1810', 'Training loss: 1.3420', '20.4521 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1684/1810', 'Training loss: 1.3419', '20.3745 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1685/1810', 'Training loss: 1.3421', '23.2136 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1686/1810', 'Training loss: 1.3420', '23.0396 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1687/1810', 'Training loss: 1.3420', '20.9209 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1688/1810', 'Training loss: 1.3417', '24.1786 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1689/1810', 'Training loss: 1.3414', '20.3394 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1690/1810', 'Training loss: 1.3417', '23.6953 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1691/1810', 'Training loss: 1.3413', '25.8227 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1692/1810', 'Training loss: 1.3414', '19.0724 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1693/1810', 'Training loss: 1.3415', '21.8787 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1694/1810', 'Training loss: 1.3420', '23.4898 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1695/1810', 'Training loss: 1.3428', '20.6454 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1696/1810', 'Training loss: 1.3423', '23.3123 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1697/1810', 'Training loss: 1.3425', '22.9598 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1698/1810', 'Training loss: 1.3420', '22.4723 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1699/1810', 'Training loss: 1.3419', '19.8308 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1700/1810', 'Training loss: 1.3418', '21.3657 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1701/1810', 'Training loss: 1.3419', '22.5089 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1702/1810', 'Training loss: 1.3421', '20.9714 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1703/1810', 'Training loss: 1.3424', '26.4701 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1704/1810', 'Training loss: 1.3426', '21.8739 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1705/1810', 'Training loss: 1.3424', '21.3812 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1706/1810', 'Training loss: 1.3426', '20.3879 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1707/1810', 'Training loss: 1.3423', '24.2596 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1708/1810', 'Training loss: 1.3418', '20.6273 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1709/1810', 'Training loss: 1.3418', '20.4286 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1710/1810', 'Training loss: 1.3417', '23.1530 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1711/1810', 'Training loss: 1.3412', '25.3710 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1712/1810', 'Training loss: 1.3411', '30.3546 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1713/1810', 'Training loss: 1.3406', '25.9205 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1714/1810', 'Training loss: 1.3402', '26.7835 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1715/1810', 'Training loss: 1.3396', '24.7291 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1716/1810', 'Training loss: 1.3390', '19.7948 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1717/1810', 'Training loss: 1.3390', '22.0273 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1718/1810', 'Training loss: 1.3388', '21.6805 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1719/1810', 'Training loss: 1.3386', '22.6058 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1720/1810', 'Training loss: 1.3382', '21.9048 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1721/1810', 'Training loss: 1.3376', '21.1234 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1722/1810', 'Training loss: 1.3376', '21.4014 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1723/1810', 'Training loss: 1.3373', '20.5371 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1724/1810', 'Training loss: 1.3371', '24.3201 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1725/1810', 'Training loss: 1.3369', '19.7633 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1726/1810', 'Training loss: 1.3366', '19.6993 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1727/1810', 'Training loss: 1.3363', '24.2356 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1728/1810', 'Training loss: 1.3359', '22.3937 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1729/1810', 'Training loss: 1.3358', '20.1493 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1730/1810', 'Training loss: 1.3353', '22.3617 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1731/1810', 'Training loss: 1.3350', '26.5306 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1732/1810', 'Training loss: 1.3345', '20.0868 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1733/1810', 'Training loss: 1.3341', '26.1199 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1734/1810', 'Training loss: 1.3341', '25.9272 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1735/1810', 'Training loss: 1.3337', '21.1107 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1736/1810', 'Training loss: 1.3334', '22.4958 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1737/1810', 'Training loss: 1.3336', '22.0251 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1738/1810', 'Training loss: 1.3333', '20.8537 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1739/1810', 'Training loss: 1.3331', '22.3200 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1740/1810', 'Training loss: 1.3328', '22.3942 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1741/1810', 'Training loss: 1.3330', '19.9242 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1742/1810', 'Training loss: 1.3331', '19.5740 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1743/1810', 'Training loss: 1.3329', '22.8678 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1744/1810', 'Training loss: 1.3328', '20.0109 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1745/1810', 'Training loss: 1.3325', '21.4065 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1746/1810', 'Training loss: 1.3323', '24.3309 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1747/1810', 'Training loss: 1.3319', '19.8108 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1748/1810', 'Training loss: 1.3317', '20.1342 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1749/1810', 'Training loss: 1.3314', '24.1705 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1750/1810', 'Training loss: 1.3312', '22.4843 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1751/1810', 'Training loss: 1.3310', '21.9784 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1752/1810', 'Training loss: 1.3309', '21.4508 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1753/1810', 'Training loss: 1.3309', '20.6539 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1754/1810', 'Training loss: 1.3305', '27.1343 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1755/1810', 'Training loss: 1.3301', '21.1555 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1756/1810', 'Training loss: 1.3297', '20.4128 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1757/1810', 'Training loss: 1.3296', '29.1007 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1758/1810', 'Training loss: 1.3295', '23.9445 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1759/1810', 'Training loss: 1.3293', '21.9216 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1760/1810', 'Training loss: 1.3291', '22.7645 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1761/1810', 'Training loss: 1.3290', '29.3764 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1762/1810', 'Training loss: 1.3288', '23.5408 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1763/1810', 'Training loss: 1.3283', '31.3655 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1764/1810', 'Training loss: 1.3281', '26.3336 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1765/1810', 'Training loss: 1.3280', '25.4570 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1766/1810', 'Training loss: 1.3278', '29.0517 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1767/1810', 'Training loss: 1.3279', '22.4987 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1768/1810', 'Training loss: 1.3279', '29.6797 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1769/1810', 'Training loss: 1.3277', '24.4402 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1770/1810', 'Training loss: 1.3278', '20.6473 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1771/1810', 'Training loss: 1.3277', '23.7219 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1772/1810', 'Training loss: 1.3277', '26.4959 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1773/1810', 'Training loss: 1.3277', '20.1453 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1774/1810', 'Training loss: 1.3278', '23.6829 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1775/1810', 'Training loss: 1.3276', '25.3572 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1776/1810', 'Training loss: 1.3276', '27.2903 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1777/1810', 'Training loss: 1.3277', '22.9438 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1778/1810', 'Training loss: 1.3278', '20.4265 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1779/1810', 'Training loss: 1.3277', '25.8668 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1780/1810', 'Training loss: 1.3277', '24.9996 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1781/1810', 'Training loss: 1.3278', '20.9968 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1782/1810', 'Training loss: 1.3280', '27.1745 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1783/1810', 'Training loss: 1.3281', '22.8099 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1784/1810', 'Training loss: 1.3278', '26.0301 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1785/1810', 'Training loss: 1.3277', '23.9078 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1786/1810', 'Training loss: 1.3274', '27.6257 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1787/1810', 'Training loss: 1.3275', '23.7843 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1788/1810', 'Training loss: 1.3273', '25.8063 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1789/1810', 'Training loss: 1.3273', '24.6242 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1790/1810', 'Training loss: 1.3274', '28.3400 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1791/1810', 'Training loss: 1.3273', '24.9927 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1792/1810', 'Training loss: 1.3270', '23.2930 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1793/1810', 'Training loss: 1.3268', '27.6004 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1794/1810', 'Training loss: 1.3267', '23.5464 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1795/1810', 'Training loss: 1.3268', '26.5848 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1796/1810', 'Training loss: 1.3269', '22.3411 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1797/1810', 'Training loss: 1.3268', '27.3462 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1798/1810', 'Training loss: 1.3267', '23.1063 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1799/1810', 'Training loss: 1.3269', '27.7556 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1800/1810', 'Training loss: 1.3270', '22.5054 sec/batch')\n",
      "('Validation loss:', 1.2180817, 'Saving checkpoint!')\n",
      "('Epoch 10/10 ', 'Iteration 1801/1810', 'Training loss: 1.3283', '22.4733 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1802/1810', 'Training loss: 1.3284', '28.0255 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1803/1810', 'Training loss: 1.3283', '21.9268 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1804/1810', 'Training loss: 1.3283', '28.1557 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1805/1810', 'Training loss: 1.3282', '23.2124 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1806/1810', 'Training loss: 1.3280', '28.3990 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1807/1810', 'Training loss: 1.3280', '22.4537 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1808/1810', 'Training loss: 1.3280', '29.7866 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1809/1810', 'Training loss: 1.3280', '29.2866 sec/batch')\n",
      "('Epoch 10/10 ', 'Iteration 1810/1810', 'Training loss: 1.3279', '21.8310 sec/batch')\n",
      "('Validation loss:', 1.2137816, 'Saving checkpoint!')\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "save_every_n = 200\n",
    "train_x, train_y, val_x, val_y = split_data(chars, batch_size, num_steps)\n",
    "\n",
    "model = build_rnn(len(vocab), \n",
    "                  batch_size=batch_size,\n",
    "                  num_steps=num_steps,\n",
    "                  learning_rate=learning_rate,\n",
    "                  lstm_size=lstm_size,\n",
    "                  num_layers=num_layers)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "    #saver.restore(sess, 'checkpoints/anna20.ckpt')\n",
    "    \n",
    "    n_batches = int(train_x.shape[1]/num_steps)\n",
    "    iterations = n_batches * epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for b, (x, y) in enumerate(get_batch([train_x, train_y], num_steps), 1):\n",
    "            iteration = e*n_batches + b\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: 0.5,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.cost, model.final_state, model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            loss += batch_loss\n",
    "            end = time.time()\n",
    "            print('Epoch {}/{} '.format(e+1, epochs),\n",
    "                  'Iteration {}/{}'.format(iteration, iterations),\n",
    "                  'Training loss: {:.4f}'.format(loss/b),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            \n",
    "            if (iteration%save_every_n == 0) or (iteration == iterations):\n",
    "                # Check performance, notice dropout has been set to 1\n",
    "                val_loss = []\n",
    "                new_state = sess.run(model.initial_state)\n",
    "                for x, y in get_batch([val_x, val_y], num_steps):\n",
    "                    feed = {model.inputs: x,\n",
    "                            model.targets: y,\n",
    "                            model.keep_prob: 1.,\n",
    "                            model.initial_state: new_state}\n",
    "                    batch_loss, new_state = sess.run([model.cost, model.final_state], feed_dict=feed)\n",
    "                    val_loss.append(batch_loss)\n",
    "\n",
    "                print('Validation loss:', np.mean(val_loss),\n",
    "                      'Saving checkpoint!')\n",
    "                saver.save(sess, \"checkpoints/anna/i{}_l{}_{:.3f}.ckpt\".format(iteration, lstm_size, np.mean(val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/anna/i3560_l512_1.122.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i200_l512_2.432.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i400_l512_1.980.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i600_l512_1.750.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i800_l512_1.595.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i1000_l512_1.484.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i1200_l512_1.407.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i1400_l512_1.349.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i1600_l512_1.292.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i1800_l512_1.255.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i2000_l512_1.224.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i2200_l512_1.204.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i2400_l512_1.187.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i2600_l512_1.172.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i2800_l512_1.160.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i3000_l512_1.148.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i3200_l512_1.137.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i3400_l512_1.129.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/anna/i3560_l512_1.122.ckpt\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints/anna')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sampling\n",
    "\n",
    "Now that the network is trained, we'll can use it to generate new text. The idea is that we pass in a character, then the network will predict the next character. We can use the new one, to predict the next one. And we keep doing this to generate all new text. I also included some functionality to prime the network with some text by passing in a string and building up a state from that.\n",
    "\n",
    "The network gives us predictions for each character. To reduce noise and make things a little less random, I'm going to only choose a new character from the top N most likely characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \"):\n",
    "    prime = \"Far\"\n",
    "    samples = [c for c in prime]\n",
    "    model = build_rnn(vocab_size, lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.preds, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.preds, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farlathit that if had so\n",
      "like it that it were. He could not trouble to his wife, and there was\n",
      "anything in them of the side of his weaky in the creature at his forteren\n",
      "to him.\n",
      "\n",
      "\"What is it? I can't bread to those,\" said Stepan Arkadyevitch. \"It's not\n",
      "my children, and there is an almost this arm, true it mays already,\n",
      "and tell you what I have say to you, and was not looking at the peasant,\n",
      "why is, I don't know him out, and she doesn't speak to me immediately, as\n",
      "you would say the countess and the more frest an angelembre, and time and\n",
      "things's silent, but I was not in my stand that is in my head. But if he\n",
      "say, and was so feeling with his soul. A child--in his soul of his\n",
      "soul of his soul. He should not see that any of that sense of. Here he\n",
      "had not been so composed and to speak for as in a whole picture, but\n",
      "all the setting and her excellent and society, who had been delighted\n",
      "and see to anywing had been being troed to thousand words on them,\n",
      "we liked him.\n",
      "\n",
      "That set in her money at the table, he came into the party. The capable\n",
      "of his she could not be as an old composure.\n",
      "\n",
      "\"That's all something there will be down becime by throe is\n",
      "such a silent, as in a countess, I should state it out and divorct.\n",
      "The discussion is not for me. I was that something was simply they are\n",
      "all three manshess of a sensitions of mind it all.\"\n",
      "\n",
      "\"No,\" he thought, shouted and lifting his soul. \"While it might see your\n",
      "honser and she, I could burst. And I had been a midelity. And I had a\n",
      "marnief are through the countess,\" he said, looking at him, a chosing\n",
      "which they had been carried out and still solied, and there was a sen that\n",
      "was to be completely, and that this matter of all the seconds of it, and\n",
      "a concipation were to her husband, who came up and conscaously, that he\n",
      "was not the station. All his fourse she was always at the country,,\n",
      "to speak oft, and though they were to hear the delightful throom and\n",
      "whether they came towards the morning, and his living and a coller and\n",
      "hold--the children. \n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"checkpoints/anna/i3560_l512_1.122.ckpt\"\n",
    "samp = sample(checkpoint, 2000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farnt him oste wha sorind thans tout thint asd an sesand an hires on thime sind thit aled, ban thand and out hore as the ter hos ton ho te that, was tis tart al the hand sostint him sore an tit an son thes, win he se ther san ther hher tas tarereng,.\n",
      "\n",
      "Anl at an ades in ond hesiln, ad hhe torers teans, wast tar arering tho this sos alten sorer has hhas an siton ther him he had sin he ard ate te anling the sosin her ans and\n",
      "arins asd and ther ale te tot an tand tanginge wath and ho ald, so sot th asend sat hare sother horesinnd, he hesense wing ante her so tith tir sherinn, anded and to the toul anderin he sorit he torsith she se atere an ting ot hand and thit hhe so the te wile har\n",
      "ens ont in the sersise, and we he seres tar aterer, to ato tat or has he he wan ton here won and sen heren he sosering, to to theer oo adent har herere the wosh oute, was serild ward tous hed astend..\n",
      "\n",
      "I's sint on alt in har tor tit her asd hade shithans ored he talereng an soredendere tim tot hees. Tise sor and \n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"checkpoints/anna/i200_l512_2.432.ckpt\"\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fard as astice her said he celatice of to seress in the raice, and to be the some and sere allats to that said to that the sark and a cast a the wither ald the pacinesse of her had astition, he said to the sount as she west at hissele. Af the cond it he was a fact onthis astisarianing.\n",
      "\n",
      "\n",
      "\"Or a ton to to be that's a more at aspestale as the sont of anstiring as\n",
      "thours and trey.\n",
      "\n",
      "The same wo dangring the\n",
      "raterst, who sore and somethy had ast out an of his book. \"We had's beane were that, and a morted a thay he had to tere. Then to\n",
      "her homent andertersed his his ancouted to the pirsted, the soution for of the pirsice inthirgest and stenciol, with the hard and and\n",
      "a colrice of to be oneres,\n",
      "the song to this anderssad.\n",
      "The could ounterss the said to serom of\n",
      "soment a carsed of sheres of she\n",
      "torded\n",
      "har and want in their of hould, but\n",
      "her told in that in he tad a the same to her. Serghing an her has and with the seed, and the camt ont his about of the\n",
      "sail, the her then all houg ant or to hus to \n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"checkpoints/anna/i600_l512_1.750.ckpt\"\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farrat, his felt has at it.\n",
      "\n",
      "\"When the pose ther hor exceed\n",
      "to his sheant was,\" weat a sime of his sounsed. The coment and the facily that which had began terede a marilicaly whice whether the pose of his hand, at she was alligated herself the same on she had to\n",
      "taiking to his forthing and streath how to hand\n",
      "began in a lang at some at it, this he cholded not set all her. \"Wo love that is setthing. Him anstering as seen that.\"\n",
      "\n",
      "\"Yes in the man that say the mare a crances is it?\" said Sergazy Ivancatching. \"You doon think were somether is ifficult of a mone of\n",
      "though the most at the countes that the\n",
      "mean on the come to say the most, to\n",
      "his feesing of\n",
      "a man she, whilo he\n",
      "sained and well, that he would still at to said. He wind at his for the sore in the most\n",
      "of hoss and almoved to see him. They have betine the sumper into at he his stire, and what he was that at the so steate of the\n",
      "sound, and shin should have a geest of shall feet on the conderation to she had been at that imporsing the dre\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"checkpoints/anna/i1000_l512_1.484.ckpt\"\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
